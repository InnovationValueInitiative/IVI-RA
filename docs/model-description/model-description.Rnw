\documentclass[11pt,final,fleqn]{article}

% basic packages
\usepackage[T1]{fontenc}
\usepackage[margin=1in] { geometry }
\usepackage{amssymb,amsmath, bm}
\usepackage{verbatim}
\usepackage[latin1]{inputenc}
%\usepackage[OT1]{fontenc}
\usepackage{setspace}
\usepackage{natbib}
\usepackage{enumitem}
\usepackage[hyphens,spaces,obeyspaces]{url}
\usepackage[font={bf}]{caption}
%\usepackage{pgfplots}
%\usepackage[font={bf}]{caption}
\usepackage{latexsym}
%\usepackage{euscript}
\usepackage{graphicx}
\usepackage{marvosym}
%\usepackage[varg]{txfonts}  Older version of ``g'' in math.
\usepackage{pdflscape}
\usepackage{algorithm}

% bibliography packages
\usepackage{natbib}
\bibpunct{(}{)}{;}{a}{}{,}
\bibliographystyle{apa}
\renewcommand{\bibname}{References}

% hyperref options
\usepackage{color}
\usepackage{hyperref}
\usepackage{xcolor}
\hypersetup{
    colorlinks,
    linkcolor={blue!50!black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black}
}
\newcommand*{\Appendixautorefname}{Appendix}
\renewcommand*{\sectionautorefname}{Section}
\renewcommand*{\subsectionautorefname}{Section}
\renewcommand*{\subsubsectionautorefname}{Section}
\newcommand{\subfigureautorefname}{\figureautorefname}
\newcommand{\aref}[1]{\hyperref[#1]{Appendix~\ref{#1}}}
\newcommand{\algorithmautorefname}{Algorithm}

% packages for tables
\usepackage{longtable}
\usepackage{booktabs, threeparttable}
\usepackage{threeparttablex}
\usepackage{tabularx}
% dcolumn package
\usepackage{dcolumn}
\newcolumntype{.}{D{.}{.}{-1}}
\newcolumntype{d}[1]{D{.}{.}{#1}}
\captionsetup{belowskip=10pt,aboveskip=-5pt}
\usepackage{multirow}
% rotating package
\usepackage[figuresright]{rotating}
\usepackage{pdflscape}
\usepackage{subcaption}
\usepackage{caption} 
\captionsetup[table]{skip=5pt}

% packages for figures
\usepackage{grffile}
\usepackage{afterpage}
\usepackage{float}
\usepackage[section]{placeins}
\usepackage[export]{adjustbox}

% theorem package
\usepackage{theorem}
\theoremstyle{plain}
\theoremheaderfont{\scshape}
\newtheorem{theorem}{Theorem}
\newtheorem{assumption}{Assumption}
\newtheorem{lemma}{Lemma}
\newtheorem{proposition}{Proposition}
\newtheorem{remark}{Remark}
\newcommand{\qed}{\hfill \ensuremath{\Box}}
\newcommand\indep{\protect\mathpalette{\protect\independenT}{\perp}}
\DeclareMathOperator{\sgn}{sgn}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\argmin}{arg\min}
\DeclareMathOperator{\argmax}{arg\max}
\def\independenT#1#2{\mathrel{\rlap{$#1#2$}\mkern2mu{#1#2}}}
\providecommand{\norm}[1]{\lVert#1\rVert}
\renewcommand\r{\right}
\renewcommand\l{\left}
\newcommand\E{\mathbb{E}}
\newcommand\dist{\buildrel\rm d\over\sim}
\newcommand\iid{\stackrel{\rm i.i.d.}{\sim}}
\newcommand\ind{\stackrel{\rm indep.}{\sim}}
\newcommand\cov{{\rm Cov}}
\newcommand\var{{\rm Var}}
\newcommand\SD{{\rm SD}}
\newcommand\bone{\mathbf{1}}
\newcommand\bzero{\mathbf{0}}
\newcommand\logit{{\rm logit}}

% file paths and definitions
\makeatletter
\newcommand*\ExpandableInput[1]{\@@input#1 }
\makeatother

% spacing 
\usepackage[compact]{titlesec}
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
\setstretch{1}

% appendix settings
\usepackage[toc,page,header]{appendix}
\renewcommand{\appendixpagename}{\centering Appendices}
\usepackage{chngcntr}
\usepackage{etoolbox}
\usepackage{lipsum}

% new commands
\newcommand\CPP{{C\texttt{++}}}
\newcommand\R{{\textsf{R}}}


% title
\title{A Description of the IVI-RA Model v0.1}
\author{Devin Incerti\footnote{Innovation and Value Initiative} \and Jeroen P. Jansen\footnote{Innovation and Value Initiative}}
\date{\today}

\begin{document}
\maketitle

\begingroup
 \hypersetup{linkcolor=black} \tableofcontents
 \listoffigures
 \listoftables
\endgroup

<<setup, include=FALSE>>=
# packages + settings
library("pander")
library("xtable")
library("iviRA")
library("data.table")
library("ggplot2")
theme_set(theme_bw())

# some functions
first_upper <- function(x) {
   substr(x, 1, 1) <- toupper(substr(x, 1, 1))
return(x)
}
@

\section{Overview}\label{overview}

This document describes version 0.1 of IVI's rheumatoid arthritis (RA) cost-effectiveness model. The IVI-RA model is an individual patient simulation (IPS) that simulates patients one at a time. The model reflects a range of perspectives (e.g., health care sector, societal) and structural assumptions. All told, there are 336 different model structures, which allows analysts to account for structural uncertainty. Parameter uncertainty is quantified with probabilistic sensitivity analysis (PSA).

The model is available as an \href{https://cran.r-project.org/}{\R{}} package with documentation available \href{https://innovationvalueinitiative.github.io/IVI-RA/index.html}{online}. The source code can be viewed or downloaded at our \href{https://github.com/InnovationValueInitiative/IVI-RA}{GitHub repository}. The IPS was primarily written in \CPP{} so that PSA and analyses of structural uncertainty can be run in a reasonable amount of time. The model can either be run using \R{} (see \href{https://innovationvalueinitiative.github.io/IVI-RA/index.html}{documentation}) or \href{http://www.shinyapps.io/}{online} with our user-friendly R Shiny web application. 

This document is structured as follows. We begin by discussing treatment strategies that can be modeled in \autoref{sec:treatments}. \autoref{sec:model-structures} outlines the competing model structures. \autoref{sec:data-parameters} describes the statistical techniques used to estimate the model parameters and the data sources used. \autoref{sec:populations} examines the data needed to define a population and run an analysis. Finally, \autoref{sec:sim-uncertainty} describes the simulation techniques used to implement the RA family of models and quantify uncertainty.

\section{Treatment strategies}\label{sec:treatments}
The primary purpose of the model is to evaluate the cost-effectiveness of treatments for RA. Since patients typically use multiple treatments over a lifetime, the model is capable of simulating a treatment sequence of any arbitrary length. Treatments that can be included in a sequence include conventional disease-modifying anti-rheumatic drugs (cDMARDs) such as methotrexate as well as the following biologic DMARDS (bDMARDs):

\begin{itemize}
\item \textbf{Tumor necrosis factor (TNF) inhibitors}: etanercept, adalimumab, infliximab, certolizumab, golimumab
\item \textbf{non-TNF inhibitors}: abatecept, tocilizumab, rituximab
\item \textbf{Janus kinase/signal transducers and activators of transcription (JAK/STAT) inhibitors}: tofacitinib
\end{itemize}

At the end of a sequence, patient switch to non-biologic therapy (NBT), which encompasses a range of therapies that do not affect the rate of disease progression and are not associated with adverse events. 

\section{Competing model structures}\label{sec:model-structures}
The IVI-RA model is a discrete-time IPS with 6 month cycles that can be run using a number of different model structures. Like most RA cost-effectiveness models, the model measures changes in disease severity using the Health Assessment Questionnaire (HAQ) Disability Index score \citep{tosh2011sheffield, carlson2015economic, stephens2015modelling, stevenson2016adalimumab, icer2017tim, stevenson2017cost}. In particular, at the start of the simulation, each patient is assigned a baseline HAQ score. Subsequently, the impact of the disease measured by the HAQ trajectory over time is modeled as a function of a sequence of treatments (\autoref{fig:haq-structure}). In the absence of treatment, HAQ deteriorates at a certain rate as depicted by the dashed line in the figure. Treatment is separated into two distinct phases: an initial phase of up to 6 months, consistent with data reported from randomized controlled trials (RCTs), and a maintenance phase thereafter until discontinuation. 

\begin{figure}
\centering
\includegraphics[max size={\textwidth}{\textheight}]{haq-structure.pdf}
\caption{Model structure regarding development of HAQ with sequential
biologic treatment}\label{fig:haq-structure}
\end{figure}

During the initial treatment phase HAQ is modeled as a change from baseline. Three possible model structures labeled \textbf{H1-H3} are possible. In \textbf{H1}, treatment influences HAQ through its effect on the American College of Rheumatology (ACR) response criteria, which is similar to the structure used in other US based cost-effectiveness models \citep[e.g.][]{carlson2015economic, icer2017tim}. ACR response is measured using four mutually exclusive categories: no response (defined as less than 20\% improvement), ACR 20-50\% improvement, ACR 50-70\% improvement, and ACR 70\% improvement or greater. The rationale for using ACR response rather than HAQ directly is that the evidence base relating treatment to ACR response is larger than the evidence based relating treatment to HAQ. \textbf{H2} follows the National Institute for Health and Care Excellence (NICE) cost-effectiveness model \citep{stevenson2016adalimumab, stevenson2017cost} and models the effect of treatment on HAQ indirectly through its effect on ACR response and, in turn, the three categories of the European League Against Rheumatism (EULAR) response (no response, moderate response, or good response). Finally, since modeling the effect of treatment on HAQ through intermediary variables may mediate treatment response, in \textbf{H3}, treatment impacts HAQ directly. The three scenarios are summarized below: 

\begin{itemize}
\item \textbf{H1}: Treatment $\rightarrow$ ACR $\rightarrow$ HAQ
\item \textbf{H2}: Treatment $\rightarrow$ ACR $\rightarrow$ EULAR $\rightarrow$ HAQ
\item \textbf{H3}: Treatment $\rightarrow$ HAQ
\end{itemize}

The probability of switching treatment during the initial treatment phase is modeled using 6 possible structures labeled \textbf{S1-S6}. \textbf{S1} follows a common approach where ACR non-responders discontinue treatment \citep[e.g.][]{carlson2015economic, icer2017tim}. One drawback of this approach is that it is not consistent with current treat-to-target guidelines in the United States \citep{singh20162015}. \textbf{S2} and \textbf{S3} consequently model treatment switching as a function of disease activity (remission, low, moderate, high) \citep{anderson2012rheumatoid}. ACR response predicts the change in disease activity from baseline, which, along with baseline disease activity, predicts absolute disease activity. The probability of switching treatment is increasing in the severity of disease (i.e., the probability is lowest in remission and greatest with high disease activity). \textbf{S2-S4} measure disease activity using the Disease Activity Score with 28-joint counts (DAS28) \citep{prevoo1995modified}, Simplified Disease Activity Index (SDAI) \citep{smolen2003simplified, aletaha2005simplified}, and Clinical Disease Activity Index (CDAI) \citep{aletaha2005acute} respectively. 

\textbf{S5} is similar to \textbf{S2-S4}, but models the effect of treatment on changes in DAS28 directly, rather than indirectly through ACR response. We also aimed to model the direct effect of treatment on SDAI and CDAI, but sufficient clinical trial data is not available. Finally, since in the UK, the British Society for Rheumatology and the British Health Professionals in Rheumatology recommends using the EULAR response \citep{deighton2010bsr}, treatment switching in \textbf{S6} depends on EULAR response. In particular, following the NICE model, we assume that EULAR non-responders discontinue treatment while moderate and good responders continue treatment \citep{stevenson2016adalimumab}. The reasoning is that rules stipulated by NICE require a DAS28 improvement of more than 1.2 to continue treatment which is associated with moderate or good EULAR response. The 6 treatment switching scenarios are summarized below: 

\begin{itemize}
\item \textbf{S1:} Treatment $\rightarrow$ ACR $\rightarrow$ Switch
\item \textbf{S2:} Treatment $\rightarrow$ ACR $\rightarrow$ $\Delta$DAS28 $\rightarrow$ DAS28 $\rightarrow$ Switch 
\item \textbf{S3:} Treatment $\rightarrow$ ACR $\rightarrow$ $\Delta$SDAI $\rightarrow$ SDAI $\rightarrow$ Switch 
\item \textbf{S4:} Treatment $\rightarrow$ ACR $\rightarrow$ $\Delta$CDAI $\rightarrow$ CDAI $\rightarrow$ Switch 
\item \textbf{S5:} Treatment $\rightarrow$ $\Delta$DAS28 $\rightarrow$ DAS28 $\rightarrow$ Switch 
\item \textbf{S6:} Treatment $\rightarrow$ ACR $\rightarrow$ EULAR $\rightarrow$ Switch
\end{itemize}

Not all model structures \textbf{S1-S6} can be used with each of \textbf{H1-H3}. If \textbf{H1} is used, then \textbf{S1-S5} are available, but \textbf{S6} is not because EULAR response is not simulated. In \textbf{H2}, \textbf{S1-S6} are all available while in \textbf{H3} only \textbf{S5} can be used since ACR response is not simulated. The 12 possible model structures and the number of each structure are outlined in \autoref{tbl:initial-model-structure}.  

\begin{table}[!ht] 
\begin{center}
\begin{threeparttable}
\caption{Model structures for initial treatment phase} \label{tbl:initial-model-structure}
\begin{tabularx}{\textwidth}{@{\extracolsep{\fill}}lcccccc}
\hline
\multicolumn{1}{l}{} & \multicolumn{1}{c}{S1} & \multicolumn{1}{c}{S2} & \multicolumn{1}{c}{S3} & \multicolumn{1}{c}{S4} & \multicolumn{1}{c}{S5} & \multicolumn{1}{c}{S6}  \\
\hline
H1 & 1 & 2 & 3 & 4 & 5 & - \\
H2 & 6 & 7 & 8 & 9 & 10 & 11 \\
H3 & - & - & - & - & 12  & -\\
\hline
\end{tabularx}
\scriptsize
Notes: Rows denote the model structure used to relate treatment to HAQ and columns denote the model structure used to predict treatment switching. Each number denotes a unique model structure (i.e. 1 corresponds to H1 and S1 and 8 corresponds to H2 and S3) and the ``-'' denotes a model structure combination that is not possible. There are 12 possible model structures for the initial treatment phase. 
\end{threeparttable}
\end{center}
\end{table}

In the maintenance phase, two model structures can be used to simulate the long-term progression of HAQ. First, as is common in cost-effectiveness analyses (CEAs) of therapies for RA, HAQ is assumed to progress at a constant linear rate over time \citep[see][]{tosh2011sheffield, wailoo2008biologic}. However, since emerging evidence suggests that the rate of HAQ progression is non-linear \citep{gibson2016haq}, our second scenario simulates HAQ progression using a latent class growth model (LCGM) \citep{norton2014health} with 4 distinct HAQ trajectories and a rate of HAQ progression that decreases over time within each trajectory. Upon discontinuation of treatment, the HAQ score rebounds by a proportion of the improvement experienced at the end of the initial 6-month period with that treatment.

The duration of the maintenance phase (i.e., time to discontinuation of maintenance treatment) is simulated using parametric time-to-event distributions. When structure \textbf{S6} is used, the time-to-event distributions are stratified by EULAR response category. Patients with good response at the end of the initial treatment phase stay on treatment longer, on average, than patients with a moderate response. In contrast, when \textbf{S1} is used, time to treatment discontinuation is simulated using a single time-to-event curve because we have been unable to obtain curves stratified by ACR response categories. Likewise, when \textbf{S2-S5} are selected, we use a single time-to-event curve because we have not obtained curves stratified by disease activity level. In each case, time to discontinuation can be simulated using one of 7 possible distributions (exponential, Weibull, Gompertz, normal, gamma, log-logistic, generalized gamma).

In line with \citet{stevenson2016adalimumab} the adverse events included in the model are limited to serious infections; we assume that only serious infections have a significant cost impact and increased risk over background rates to be meaningful to include \citep{ramiro2017safety}. While on a treatment, a patient experiences a serious infection if the individual's sampled time to the adverse event is shorter than the sampled time to treatment discontinuation.

Baseline HAQ scores (and changes in HAQ scores from baseline) are used to determine mortality relative to age/sex specific rates for the US general population (assumed to have a HAQ score of 0). Treatment therefore has an indirect effect on mortality through its effect on HAQ. 

Individual HAQ scores at a particular point in time were also used to simulate EQ-5D utility scores (0-1 range), which, in turn, were used to simulate quality-adjusted life-years (QALYs). However, since a number of different methods have been used to convert HAQ into utility, our model contains two different possible mapping algorithms. Our preferred algorithm is the \citet{alava2013relationship} mixture model, which uses a much larger sample size than other statistical models and has been shown to have better predictive accuracy. Other algorithms are typically estimated using clinical trial data \citep[e.g.][]{carlson2015economic, stephens2015modelling} and consequently have limited generalizability. The second utility algorithm available within our model is based on a linear regression analysis of real-world data by \citet{wailoo2006modeling} that has been used in a few previous CEAs \citep[e.g.][]{wailoo2008biologic, icer2017tim}. 

Annual hospitalization days and productivity losses are simulated as a function of HAQ. Health sector costs considered in the models are related to drug acquisition and administration, adverse events, general management of RA, and hospitalization. Non-health sector costs considered are limited to work related productivity loss.

Patient preferences for treatment attributes have a direct effect on long-term treatment duration and utility. Patients with treatments that more closely match their preferences have longer treatment duration and higher utility. Treatment attributes that are incorporated into the models include route of administration and frequency of administration.

The flow diagram in \autoref{fig:flow-diagram} describes the flow of a single patient through the simulation. Each patient begins the simulation by initiating treatment and ends the simulation with death. The rectangles in the figure represent ``processes'' determining the effect of treatment on disease progression and the diamonds represent ``decisions'' that determine whether a patient will switch to a new treatment.

\begin{figure}
\centering
\includegraphics[max size={\textwidth}{\textheight}]{flow-diagram.png}
\caption{Flow diagram of the simulation for a single
patient}\label{fig:flow-diagram}
\end{figure}

The influence diagram in \autoref{fig:influence-diagram} summarizes the assumed structural relationships among different variables in the model. Each arrow represents the direct effect of one parameter on another. Dashed lines represent relationships that depend on the structural assumptions used. \autoref{subfig:treatment-effects} focuses on the effect of treatment on disease progression and adverse events while \autoref{subfig:model-outcomes} looks at the variables influencing the primary health and cost outcomes. 

Model outcomes depend on patient characteristics, which have a direct effect on HAQ progression, mortality, and utility. The primary health outcome is the quality-adjusted life-year (QALY), which depends on mortality and utility. Total costs consist of health care sector costs and productivity losses. The components of health sector costs include drug acquisition and administration costs, general management and monitoring costs, adverse event costs, and hospitalization costs  Analyses from a societal perspective would include productivity losses while analyses from a health care sector perspective would not. The value of treatment is estimated using the net-monetary benefit (NMB), which is calculated by multiplying QALYs by a willingness to pay threshold and subtracting costs ($NMB = QALYs \cdot WTP - Costs$). 

\begin{figure}
\centering
\begin{subfigure}{\textwidth}
\includegraphics[width=\textwidth]{influence-diagram-a.png}
\caption{Treatment effects} \label{subfig:treatment-effects}
\end{subfigure}
\begin{subfigure}{\textwidth}
\includegraphics[width=\textwidth]{influence-diagram-b.png}
\caption{Model outcomes} \label{subfig:model-outcomes}
\end{subfigure}
\caption{Influence diagram outlining structural relationships}\label{fig:influence-diagram}
\begin{minipage}{\linewidth}
\footnotesize
Notes: ACR: American College of Rheumatology; EULAR: European League Against Rheumatism; HAQ: Health Assessment Questionnaire; QALY: AEs: adverse events; QALYs: quality-adjusted life-years; WTP: willingness to pay. Disease activity refers to the Disease Activity Score with 28-joint counts (DAS28) or the Simplified Disease Activity Index (SDAI).
\end{minipage}
\end{figure}

\autoref{tbl:competing-structures} summarizes the competing model structures, which are conditional on the perspective of the decision maker. In total, there are 12 x 2 x 7 x 2 = 336 possible model structures.

\renewcommand{\arraystretch}{1.5}

\begin{table}[!ht]
\begin{center}
\begin{threeparttable}
\caption{Competing model structures} \label{tbl:competing-structures}
\begin{tabular}{p{0.80\linewidth}p{0.20\linewidth}}
\hline
\multicolumn{1}{c}{Component of model structure} & \multicolumn{1}{c}{Possible combinations} \\
\hline
Initial effect of treatment on HAQ (\textbf{H1-H3}) and switching (\textbf{S1-S6}) & 12  \\
HAQ trajectory & 2 \\
Probability distribution for treatment duration & 7 \\
Utility algorithm & 2 \\
\hline
\end{tabular}
\end{threeparttable}
\end{center}
\end{table}\renewcommand{\arraystretch}{1}

\section{Populations}\label{sec:populations}
To run the IPS, a patient population must be specified. The model is designed for patients who are cDMARD experienced. The patient characteristics that must be included in the analysis are age, HAQ, gender, weight, disease duration (in months), the number of previous DMARDs, and disease activity. These variables are measured at the start of the simulation (i.e., model cycle 0).  

Two default options for the patient population are available. First, a homogeneous cohort of men and women with gender-specific weights but otherwise identical characteristics can be used. Second, a heterogeneous cohort of patients with gender-specific weights but varying across all other characteristics can be specified. Other populations (i.e., for certain subgroups or based on registry data) can be used as well but are not prespecified in our \R{} package. 

<<pop, echo = FALSE, include = FALSE>>=
args <- formals(sample_pats)
mean <- c(args$age_mean, args$male_prop, args$wtfemale, args$wtmale, args$dis_dur_mean,
          args$prev_dmards_mean, args$das28_mean, args$sdai_mean, args$cdai_mean, args$haq0_mean)
mean <- formatC(mean, format = "f", digits = 2)
sd <-  c(args$age_sd, 0, 0, 0, args$dis_dur_sd,
          args$prev_dmards_sd, args$das28_sd, args$sdai_sd, args$cdai_sd, args$haq0_sd)
sd <- formatC(sd, format = "f", digits = 2)
sd[sd == "0.00"] <- "-"
vars <- c("Age", "Male", "Female weight (kg)", "Male weight (kg)", "Disease duration", 
          "Previous   DMARDs","DAS28", "SDAI", "CDAI", "HAQ") 
min <- c(18, "-", "-", "-", rep(0, 6))
max <- c(85, rep("-", 5), 9.4, 86, 76, 3)
tab <- data.frame(var = vars, mean = mean, sd = sd, min, max)
tex <- print(xtable(tab), 
      include.rownames = FALSE, include.colnames = FALSE,
      only.contents = TRUE, sanitize.text.function = identity,
      file = "tables/pat-inputs.txt")
@

Our default population consists of individuals that, on average, have high disease activity. The proportion that is female, age, disease duration, the number of previous DMARDs, baseline HAQ, and DAS28 are based on the values reported in \citet{curtis2010comparison}. Mean values for the SDAI and CDAI are from the US301 clinical trial---which had a DAS28 score similar to the value from \citet{curtis2010comparison}---summarized in \citet{smolen2003simplified}. Summaries of each variable are reported in \autoref{pats}. Details on the algorithm for simulating heterogeneous paients are described in \autoref{app:population}.

\begin{table}[!ht]
\begin{center}
\begin{threeparttable}
\caption{Default inputs for patient population} \label{tbl:pats}
\begin{tabularx}{\textwidth}{@{\extracolsep{\fill}}lcccc}
\hline
\multicolumn{1}{l}{} & \multicolumn{1}{c}{Mean} & \multicolumn{1}{c}{Standard deviation} & \multicolumn{1}{c}{Minimum} & \multicolumn{1}{c}{Maximum}\\
\hline
\ExpandableInput{tables/pat-inputs.txt}
\hline
\end{tabularx}
\scriptsize
\end{threeparttable}
\end{center}
\end{table}

\section{Source data and parameter estimation}\label{sec:data-parameters}
\subsection{Comparative treatment efficacy from NMA}\label{nma-parameters}

The effects of treatment on ACR response, DAS28, and HAQ at 6 months are estimated using Bayesian network meta-analyses (NMA) of published randomized controlled trials (RCTs). Primary outcomes were ACR response, change in DAS28 from baseline at 6 months, and the change in HAQ from baseline at 6 months. Details of the methodology are provided in the Appendix (\autoref{app:nma-statistical-models}).

<<nma_results, cache=TRUE, echo=FALSE, include=FALSE>>=
arm.snames <- c("cdmards", "abtivmtx", "adamtx", "etnmtx", "golmtx", "ifxmtx", "tczmtx", "czpmtx",
                          "abtscmtx", "rtxmtx", "tofmtx")
arminds <- which(therapy.pars$info$sname %in% arm.snames)
arm.names <- therapy.pars$info[sname %in% arm.snames, mname]
parsamp <- sample_pars(n = 1000)
format_table <- function(m, l, u, digits = 3){
  m <- formatC(m, format = "f", digits = digits)
  l <- formatC(l, format = "f", digits = digits)
  u <- formatC(u, format = "f", digits = digits)
  m <- trimws(m); l <- trimws(l); u <- trimws(u)
  m[m == "NA"] <- ""
  l[l == "NA"] <- ""
  u[u == "NA"] <- ""
  tab <- paste0(m, " (", l, ", ", u, ")")
  tab[tab == " (, )"] <- "-"
  if (is.matrix(m)){
      tab <- matrix(tab, nrow = nrow(m), ncol = ncol(m))
  }  
  return(tab)
} 

# ACR response
acr <- parsamp$acr$p1.overlap 
acr.mean <- formatC(apply(acr, c(3, 2), mean), format = "f", digits = 3)
acr.l <- formatC(apply(acr, c(3, 2), quantile, .025, na.rm = TRUE), format = "f", digits = 3)
acr.u <- formatC(apply(acr, c(3,2), quantile, .975, na.rm = TRUE), format = "f", digits = 3)
acr.tab <- format_table(acr.mean, acr.l, acr.u, digits = 3)
acr.tab <- acr.tab[arminds, ]
rownames(acr.tab) <- arm.names

# DAS28
das28 <- parsamp$das28$dy1
das28.mean <- apply(das28, 2, mean)
das28.l <- apply(das28, 2, quantile, .025, na.rm = TRUE)
das28.u <- apply(das28, 2, quantile, .975, na.rm = TRUE)
das28.tab <- format_table(das28.mean, das28.l, das28.u, digits = 3)
das28.tab <- das28.tab[arminds]

# HAQ
haq <- parsamp$haq$dy1
haq.mean <- apply(haq, 2, mean)
haq.l <- apply(haq, 2, quantile, .025, na.rm = TRUE)
haq.u <- apply(haq, 2, quantile, .975, na.rm = TRUE)
haq.tab <- format_table(haq.mean, haq.l, haq.u, digits = 3)
haq.tab <- haq.tab[arminds]

# Tex table
tab <- cbind(acr.tab[, -1], das28.tab, haq.tab)
tex <- print(xtable(tab),
       include.rownames = TRUE, include.colnames = FALSE,
       only.contents = TRUE, sanitize.text.function = identity,
       file = "tables/nma-acr-das28-haq.txt")
@

\begin{landscape}
\begin{table}[!ht]
\begin{center}
\begin{threeparttable}
\caption{NMA estimates of ACR response, change in DAS28, and change in HAQ for biologic naive patients} \label{tbl:nma-acr-das28-haq}
\small
\begin{tabular}{lccccc}
\hline
\multicolumn{1}{c}{} & \multicolumn{3}{c}{ACR response} & \multicolumn{2}{c}{}\\
\cmidrule(lr){2-4} 
\multicolumn{1}{l}{} & \multicolumn{1}{c}{ACR20} & \multicolumn{1}{c}{ACR50} & \multicolumn{1}{c}{ACR70} & \multicolumn{1}{c}{$\Delta$DAS28} & \multicolumn{1}{c}{$\Delta$HAQ} \\
\hline
\ExpandableInput{tables/nma-acr-das28-haq.txt}
\hline
\end{tabular}
\scriptsize
Notes: ACR20/50/70 categories are the probability of at least a 20/50/70\% improvement. 95\% credible intervals are in parentheses. Estimates are based on 1,000 random draws of the NMA parameters. $\Delta$DAS28 and $\Delta$HAQ are changes in the DAS28 and HAQ score from their baseline scores respectively; negative numbers denote reductions in baseline values. cDMARDs = conventional disease-modifying antirheumatic drugs; MTX = methotrexate; ABT IV = abatacept intravenous; ADA = adalimumab; ETN = etanercept; GOL = golimumab; IFX = infliximab; TCZ = tocilizumab; CZP = certolizumab pegol; ABT SC = abatacept subcutaneous; RTX = rituximab; TOF = tofacitinib. ACR = American College of Rheumatology.
\end{threeparttable}
\end{center}
\end{table}
\end{landscape}

\subsection{Treatment switching at 6 months}
\subsubsection{ACR response and change in disease activity}
There are currently no established mappings between mutually exclusive ACR response categories and DAS28, SDAI, or CDAI \citep{madan2015consensus}. However, \citet{aletaha2005simplified} provides evidence on the relationship between overlapping ACR response categories (ACR 20/50/70) and mean changes in each of the three disease activity measures. Results are reported for three cohorts---the Leflunomide datasets, the inception cohort, and the routine cohort---with 1,839, 91, and 279 patients respectively. We transformed mean changes by overlapping ACR response categories to mean changes by mutually exclusive ACR response categories (ACR < 20, ACR 20-50, ACR 50-70, ACR 70+) by using the number of patients in each mutually exclusive ACR response category as described in \autoref{app-acr-da}. \citet{smolen2003simplified} provided the number of patients in each ACR response category in the Leflunomide dataset and \citet{aletaha2005acute} provided the number of patients in the inception cohort. Mean changes in each mutually exclusive ACR response category are shown in \autoref{tbl:acr2da}.

<<acr2da, echo = FALSE, include = FALSE>>=
tab <- cbind(acr2sdai$leflunomide$mean, acr2sdai$inception$mean,
             acr2cdai$inception$mean, acr2das28$inception$mean)
tab <- formatC(tab, format = "f", digits = 3)
rownames(tab) <- c("<20", "20-50", "50-70", "70+")
tex <- print(xtable(tab), 
      include.rownames = TRUE, include.colnames = FALSE,
      only.contents = TRUE, sanitize.text.function = identity,
      file = "tables/acr2da.txt")
@

\begin{table}[!ht]
\begin{center}
\begin{threeparttable}
\caption{Relationship between ACR response and change in disease activity measures} \label{tbl:acr2da}
\begin{tabularx}{\textwidth}{@{\extracolsep{\fill}}lcccc}
\hline
\multicolumn{1}{l}{ACR response} &  \multicolumn{3}{c}{Mean change at 6 months}\\
\cmidrule{2-5}
\multicolumn{1}{l}{} & \multicolumn{1}{c}{Leflunomide dataset} & \multicolumn{3}{c}{Inception cohort}\\
\cmidrule(lr){2-2}  \cmidrule(lr){3-5}
\multicolumn{1}{c}{} & \multicolumn{1}{c}{SDAI} & \multicolumn{1}{c}{SDAI} &\multicolumn{1}{c}{CDAI} & \multicolumn{1}{c}{DAS28} \\
\hline
\ExpandableInput{tables/acr2da.txt}
\hline
\end{tabularx}
\scriptsize
\end{threeparttable}
\end{center}
\end{table}

We did not include estimates from the routine cohort for two reasons. First, we were unable to find information on the number of patients in each ACR response category. Second, patients in the routine cohort had considerably lower disease activity levels \citep{aletaha2005simplified, aletaha2005acute} and our main population of interest (see \autoref{sec:populations}) consists of patients with high disease activity at baseline. Mean DAS28 in the inception cohort and routine cohort were 5.62, and 4.09 respectively, while the mean DAS 28 ranged from 6.3 to 7 across the clinical trials making up the Leflunomide dataset.

\subsubsection{ACR response and change in EULAR response}
ACR responses were translated into EULAR response probabilities based on evidence of their relationship reported in \citet{stevenson2016adalimumab} and obtained from the US Veterans Affairs Rheumatoid Arthritis (VARA) registry (\autoref{tbl:acr2eular}).

<<acr2eular, echo = FALSE, include = FALSE>>=
tab <- acr2eular
tab <- formatC(tab, format = "d", big.mark = ",")
rownames(tab) <- c("<20", "20-50", "50-70", "70+")
tex <- print(xtable(tab), 
      include.rownames = TRUE, include.colnames = FALSE,
      only.contents = TRUE, sanitize.text.function = identity,
      file = "tables/acr2eular.txt")
@

\begin{table}[!ht]
\begin{center}
\begin{threeparttable}
\caption{Relationship between ACR response and EULAR response} \label{tbl:acr2eular}
\begin{tabularx}{\textwidth}{@{\extracolsep{\fill}}lcccc}
\hline
\multicolumn{1}{l}{} & \multicolumn{3}{c}{EULAR response} \\
\cmidrule{2-4} 
\multicolumn{1}{c}{ACR response} & \multicolumn{1}{c}{None} & \multicolumn{1}{c}{Moderate} & \multicolumn{1}{c}{Good} \\
\hline
\ExpandableInput{tables/acr2eular.txt}
\hline
\end{tabularx}
\scriptsize
Notes: The VARA registry is a multicentre, US database of veterans age 19 and older. Each cell represents the number of patients in the 
database in a given category. 
\end{threeparttable}
\end{center}
\end{table}

\subsubsection{Probability of switching treatment}
<<treat-switch, echo = FALSE, include = FALSE>>=
tab <- treat.switch[, .(p, p_lower, p_upper)]
p.low <- treat.switch[disease_activity == "Low", p]
p.moderate <- treat.switch[disease_activity == "Moderate", p]
p.high <- treat.switch[disease_activity == "High", p]
tab <- cbind(c("CDAI $\\leq 2.8$", "CDAI >2.8-10 (low)", 
               "CDAI >10-22 (moderate)", "CDAI $\\geq 22$"), 
             formatC(as.matrix(tab), format = "f", digits = 3))
tex <- print(xtable(tab), 
      include.rownames = FALSE, include.colnames = FALSE,
      only.contents = TRUE, sanitize.text.function = identity,
      file = "tables/treat-switch.txt")
@

The probability of stopping treatment depends on the model structure used. If \textbf{S1} or \textbf{S6} is used, then patients stop treatment when there is no ACR response or no EULAR response, and continue treatment otherwise. If switching depends on SDAI, CDAI, or DAS28, then we model the probability of treatment switching and adjust it according to the level of disease activity. 

\begin{table}[!ht]
\begin{center}
\begin{threeparttable}
\caption{Estimated probability of switching treatment at 6 months} \label{tbl:logistic-treat-switch}
\begin{tabularx}{\textwidth}{@{\extracolsep{\fill}}lccc}
\hline
\multicolumn{2}{l}{} & \multicolumn{2}{c}{95\% CI} \\
\cmidrule{3-4} 
\multicolumn{1}{c}{Variable} & \multicolumn{1}{c}{Estimate} & \multicolumn{1}{c}{Lower} & \multicolumn{1}{c}{Upper} \\
\hline
\ExpandableInput{tables/treat-switch.txt}
\hline
\end{tabularx}
\scriptsize
Notes: Coefficients are log odds ratios. CDAI <10 (low) is a reference category. 
\end{threeparttable}
\end{center}
\end{table}

The probability of treatment switching is estimated using a logistic regression equation. Differences in discontinuation by disease activity level are based on the odds ratios reported in \citet{zhang2011thresholds} from an analysis of the Consortium of Rheumatology Researchers of North America (CORRONA) database. \citet{zhang2011thresholds} estimated odds ratios for three disease activity categories based on CDAI (<10 (low), 10-22 (moderate), and $\geq$ 22 (high)). We set the intercept in our logistic regression equation so that the probability of treatment switching for a patient with moderate disease activity is \Sexpr{p.moderate*100}\%. This assumption is based on an estimate of the probability of treatment discontinuation at 6 months from a Kaplan-Meier curve estimated using the Consortium of Rheumatology Researchers of North America (CORRONA) database (see \autoref{sec:ttd-corrona} for more details)---a population that tended to have moderate disease activity (mean CDAI = 16.0)---and is consistent with ranges from the literature \citep{souto2015rate}. The standard error of the intercept was set so that the probability of switching with moderate disease activity varied by $\pm$ 3\%. The coefficients for all variables in the logistic regression equations are shown in \autoref{tbl:logistic-treat-switch}.   

In the IPS, we use the absolute level of disease activity at 6 months (not at baseline) to make predictions. We define low, moderate, and high disease activity when using DAS28 and SDAI as in \citet{anderson2012rheumatoid}. The predicted probabilities of switching at 6 months for low, medium and high disease activity patients are \Sexpr{formatC(p.low*100, format = "f", digits = 1)}\%, \Sexpr{formatC(p.moderate*100, format = "f", digits = 1)}\%, and \Sexpr{formatC(p.high*100, format = "f", digits = 1)}\% respectively. 

\subsection{Change in HAQ at 6 months}
As in \citet{icer2017tim}, ACR responses from the NMA were translated into HAQ scores based on evidence from the ADACTA trial reported in \citet{carlson2015economic} (\autoref{tbl:acr2haq}).

<<acr2haq, echo = FALSE, include = FALSE>>=
tab <- formatC(as.matrix(acr2haq[, .(mean, se)]))
rownames(tab) <- c("<20", "20-50", "50-70", "70+")
tex <- print(xtable(tab), 
      include.rownames = TRUE, include.colnames = FALSE,
      only.contents = TRUE, sanitize.text.function = identity,
      file = "tables/acr2haq.txt")
@

\begin{table}[!ht]
\begin{center}
\begin{threeparttable}
\caption{Relationship between ACR response and change in HAQ at 6 months} \label{tbl:acr2haq}
\begin{tabularx}{\textwidth}{@{\extracolsep{\fill}}lcc}
\hline
\multicolumn{1}{l}{} & \multicolumn{2}{c}{HAQ change} \\
\cmidrule{2-3} 
\multicolumn{1}{c}{ACR response} & \multicolumn{1}{c}{Mean} & \multicolumn{1}{c}{Standard error} \\
\hline
\ExpandableInput{tables/acr2haq.txt}
\hline
\end{tabularx}
\scriptsize
Source: \citet{carlson2015economic}
\end{threeparttable}
\end{center}
\end{table}

<<eular2haq, echo = FALSE, include = FALSE>>=
eular2haq.f <- formatC(as.matrix(eular2haq[, .(mean, se)]), format = "f", digits = 3)
rownames(eular2haq.f) <- c("None", "Moderate", "Good")
tex <- print(xtable(eular2haq.f), 
      include.rownames = TRUE, include.colnames = FALSE,
      only.contents = TRUE, sanitize.text.function = identity,
      file = "tables/eular2haq.txt")
@

The relationship between EULAR response and HAQ is based on analyses conducted by \citet{stevenson2016adalimumab} using the BSRBR database. Their analysis is based on predictions from a mixture model with covariates set to sample means. Moderate and good EULAR responses are associated with \Sexpr{eular2haq.f[2, "mean"]} (SE = \Sexpr{eular2haq.f[2, "se"]}) and \Sexpr{eular2haq.f[3, "mean"]} (SE = \Sexpr{eular2haq.f[3, "se"]}) changes in HAQ scores respectively (\autoref{tbl:eular2haq}). 

\begin{table}[!ht]
\begin{center}
\begin{threeparttable}
\caption{Relationship between EULAR response and HAQ} \label{tbl:eular2haq}
\begin{tabularx}{\textwidth}{@{\extracolsep{\fill}}lcc}
\hline
\multicolumn{1}{c}{EULAR response} & \multicolumn{1}{c}{Mean} & \multicolumn{1}{c}{SE} \\
\hline
\ExpandableInput{tables/eular2haq.txt}
\hline
\end{tabularx}
\scriptsize
%Notes: 
\end{threeparttable}
\end{center}
\end{table}

\autoref{tbl:sim-haq-change} compares the impact of treatment on HAQ using model structures \textbf{H1-H3}.

<<sim_haq_change, cache=TRUE, echo=FALSE, include=FALSE>>=
arm.snames <- c("cdmards", "abtivmtx", "adamtx", "etnmtx", "golmtx", "ifxmtx", "tczmtx", "czpmtx",
                          "abtscmtx", "rtxmtx", "tofmtx")
arminds <- as.list(which(therapy.pars$info$sname %in% arm.snames))
arm.names <- therapy.pars$info[sname %in% arm.snames, mname]
ir <- function(arminds, arm_names, nouter = 1000, ninner = 1000, treat_hist = "naive"){
  acr.mean <- matrix(NA, nrow = length(arminds), ncol = 4)
  acr.o.mean <- matrix(NA, nrow = length(arminds), ncol = 3)
  acr.lower <- acr.upper <- acr.mean
  acr.o.lower <- acr.o.upper <- acr.o.mean 
  eular.mean <- matrix(NA, nrow = length(arminds), ncol = 3)
  eular.lower <- eular.upper <- eular.mean
  dhaq.mean <- dhaq.lower <- dhaq.upper <- rep(NA, length(arminds))
  pat <- sample_pats(n = ninner)
  input.dat <- input_data(patdata = pat)
  parsamp <- sample_pars(n = nouter, treat_hist = treat_hist)
  for (i in 1:length(arminds)){
    sim6 <- sim_haq(arminds[[i]], input_data = input.dat, pars = parsamp, max_months = 6)

    ## acr
    acr.full <- data.table(sim = rep(seq(1, ninner) , 4),
                            acr = rep(seq(0, 3), each = ninner))
    acr <- setkey(sim6, sim, acr)[acr.full, .(prop = .N/ninner), by=.EACHI]
    acr <- dcast(acr, sim ~ acr, value.var = "prop")
    acr[is.na(acr)] <- 0
    acr <- as.matrix(acr)[, -1, drop = FALSE]
    acr.o <- matrix(NA, nrow = ninner, ncol  = 3)
    acr.o[, 1] <- 1 - acr[, 1] # ACR 20
    acr.o[, 2] <- acr[, 3] + acr[, 4] # ACR 50
    acr.o[, 3] <- acr[, 4] # ACR 70
    
    # quantiles
    acr.mean[i, ] <- apply(acr, 2, mean)
    acr.lower[i, ] <- apply(acr, 2, quantile, .025)
    acr.upper[i, ] <- apply(acr, 2, quantile, .975)
    acr.o.mean[i, ] <- apply(acr.o, 2, mean)
    acr.o.lower[i, ] <- apply(acr.o, 2, quantile, .025)
    acr.o.upper[i, ] <- apply(acr.o, 2, quantile, .975)

    ## eular
    eular.full <- data.table(sim = rep(seq(1, ninner) - 1, 3),
                           eular = rep(seq(0, 2), each = ninner))
    eular <- setkey(sim6, sim, eular)[eular.full, .(prop = .N/ninner), by=.EACHI]
    eular <- dcast(eular, sim ~ eular, value.var = "prop")
    eular[is.na(eular)] <- 0
    eular <- as.matrix(eular)[, -1]
    eular.mean[i, ] <- apply(eular, 2, mean)
    eular.lower[i, ] <- apply(eular, 2, quantile, .025)
    eular.upper[i, ] <- apply(eular, 2, quantile, .975)

    ## haq change mean
    dhaq <- sim6$haq - input.dat$haq0[sim6$id]
    dhaq.mean[i] <- mean(dhaq)
    dhaq.lower[i] <- quantile(dhaq, .025)
    dhaq.upper[i] <- quantile(dhaq, .975)

    print(i)
  }
  return(list(arm.names = arm_names,
              acr.lower = acr.lower, acr.mean = acr.mean, acr.upper = acr.upper,
              acr.o.lower = acr.o.lower, acr.o.mean = acr.o.mean , acr.o.upper = acr.o.upper, 
              eular.lower = eular.lower, eular.mean = eular.mean, eular.upper = eular.upper,
              dhaq.lower = dhaq.lower, dhaq.mean = dhaq.mean, dhaq.upper = dhaq.upper))
}
ir_table <- function(x, digits = 2){
  # table output
  table.mean <- cbind(x$acr.mean, x$acr.o.mean, x$eular.mean, x$dhaq.mean)
  table.lower <- cbind(x$acr.lower, x$acr.o.lower, x$eular.lower, x$dhaq.lower)
  table.upper <- cbind(x$acr.upper, x$acr.o.upper, x$eular.upper, x$dhaq.upper)
  ftable.mean <- formatC(table.mean, format = "f", digits = digits)
  ftable.lower <- formatC(table.lower, format = "f", digits = digits)
  ftable.upper <- formatC(table.upper, format = "f", digits = digits)
  ftable <- paste0(ftable.mean, " (", ftable.lower, ", ", ftable.upper, ")")
  ftable <- matrix(ftable, nrow = nrow(ftable.mean), ncol = ncol(ftable.mean))
  cn <- c("acrl20", "acr20-50", "acr50-70", "acr70+", "acr20", "acr50", "acr70",
                           "eular_nr", "eular_mr", "eular_gr", "eular_dhaq")
  colnames(ftable) <- cn
  rownames(ftable) <- x$arm.names
  return(ftable)
}
sim.ir.naive <- ir(arminds, arm.names, treat_hist = "naive")
#sim.ir.exp <- ir(arminds, arm.names, treat_hist = "exp")
tab.naive <- ir_table(sim.ir.naive)
#tab.exp <- ir_table(sim.ir.exp)
acr_dhaq <- NA
dhaq <- NA
tab.naive <- cbind(tab.naive, acr_dhaq, dhaq)

# TEX table
tab <- tab.naive[, c("acr_dhaq", "dhaq", "eular_nr", "eular_mr", "eular_gr", "eular_dhaq")]
tex <- print(xtable(tab),
      include.rownames = TRUE, include.colnames = FALSE,
      only.contents = TRUE, sanitize.text.function = identity,
      file = "tables/sim-dhaq-6months.txt")
@

\begin{landscape}
\begin{table}[!ht]
\begin{center}
\begin{threeparttable}
\caption{Simulated change in HAQ at 6 months under different model structures} \label{tbl:sim-haq-change}
\scriptsize
\begin{tabular}{lcccccc}
\hline
\multicolumn{1}{c}{} & \multicolumn{1}{c}{\textbf{H1}} & \multicolumn{1}{c}{\textbf{H2}} & \multicolumn{4}{c}{\textbf{H3}} \\
\cmidrule(lr){2-2} \cmidrule(lr){3-3}  \cmidrule(lr){4-7} 
\multicolumn{1}{l}{} & \multicolumn{1}{c}{$\Delta$HAQ} & \multicolumn{1}{c}{$\Delta$HAQ} & \multicolumn{1}{c}{EULAR no response} & \multicolumn{1}{c}{EULAR moderate response} & \multicolumn{1}{c}{EULAR good response} & \multicolumn{1}{c}{$\Delta$HAQ}\\
\hline
\ExpandableInput{tables/sim-dhaq-6months.txt}
\hline
\end{tabular}
\scriptsize
Notes: 95\% credible intervals are in parentheses. Estimates are based on 6-month simulations of 1,000 patients and 1,000 parameters sets for each therapy. $\Delta$HAQ denotes a change in the HAQ score at 6 months from baseline; a negative value indicates a reduction in the HAQ score. cDMARDs = conventional disease-modifying antirheumatic drugs; MTX = methotrexate; ABT IV = abatacept intravenous; ADA = adalimumab; ETN = etanercept; GOL = golimumab; IFX = infliximab; TCZ = tocilizumab; CZP = certolizumab pegol; ABT SC = abatacept subcutaneous; RTX = rituximab; TOF = tofacitinib. ACR = American College of Rheumatology.
\end{threeparttable}
\end{center}
\end{table}
\end{landscape}


\subsection{HAQ progression in the absence of bDMARD treatment}\label{haq-progression-in-the-absence-of-bdmard-treatment}

The natural course of HAQ progression in the absence of bDMARDs develops over time according to an estimated natural course for patients remaining on cDMARDs or following discontinuation of the last bDMARD of the sequence. The natural course of HAQ can either be assumed to change at a constant linear rate or be modeled using a non-linear mixture model. 

\subsubsection{Constant linear rate of progression} \label{sec:haq-linear-rate}
The rate of progression in the linear case is based on the observational study by \citet{wolfe2010loss}. They assessed the development of HAQ over time at six month intervals for up to 11 years among 3,829 RA patients who switched from non-biologic treatment to biologic treatment and participated in the National Data Bank for Rheumatic Diseases (NDB) longitudinal study of RA outcomes. The annual HAQ progression rate prior to biologic therapy was 0.031 (95\% confidence interval (95\%CI): 0.026 to 0.036) and is assumed to reflect the course of progression of HAQ in the absence of bDMARD.

Based on the same data, \citet{michaud2011treatment} reported overall and age-specific specific HAQ progression rates. The differences between the overall and age specific rates are as follows: \textless{}40: -0.020 (95\%CI: -0.0223 to -0.0177); 40-64: -0.008 (95\%CI: -0.0101 to -0.0059); \(\geq\) 65 0.017 (95\%CI: 0.0136 to 0.0204). These estimates are applied to the overall progression rate of 0.031 to obtain age specific HAQ progression rates (see \autoref{app:age-linear-haq}).

<<haq_lp, echo = FALSE, include = FALSE>>=
tab1 <- therapy.pars$haq.lprog[sname == "cdmards", .(est, lower, upper)]
tab1 <- formatC(as.matrix(tab1), format = "f", digits = 3)
tab1 <- cbind(tab1, "\\citet{wolfe2010loss}")
tab1 <- cbind("\\hspace{3mm}MTX or non-biologic treatment", tab1)
tex1 <- print(xtable(tab1), 
      include.rownames = FALSE, include.colnames = FALSE,
      only.contents = TRUE, sanitize.text.function = identity, hline.after = NULL,
      file = "tables/haq-lprog-cdmards.txt")

tab2 <- haq.lprog.age[, .(est, lower, upper)] 
tab2 <- formatC(as.matrix(tab2), format = "f", digits = 3)
tab2 <- cbind(paste0("\\hspace{3mm}", c("<40", "40-64", "65+")), 
                   tab2)
tab2 <- cbind(tab2, "\\citet{michaud2011treatment}")
tex2 <- print(xtable(tab2), 
      include.rownames = FALSE, include.colnames = FALSE,
      only.contents = TRUE, sanitize.text.function = identity, hline.after = NULL,
      file = "tables/haq-lprog-diff-byage.txt")
@

\begin{table}[!ht]
\begin{center}
\begin{threeparttable}
\caption{Annual linear progression of HAQ in the absence of bDMARDs beyond 6 months} \label{tbl:haq-lprog}
\footnotesize
\begin{tabularx}{\textwidth}{@{\extracolsep{\fill}}lrrrl}
\hline
\multicolumn{2}{l}{} & \multicolumn{2}{c}{95\% CI} & \multicolumn{1}{l}{} \\
\cmidrule{3-4} 
\multicolumn{1}{l}{} & \multicolumn{1}{r}{Estimate} & \multicolumn{1}{r}{Lower} & \multicolumn{1}{r}{Upper} & \multicolumn{1}{l}{Reference} \\
\hline
Overall progression rate \\
\ExpandableInput{tables/haq-lprog-cdmards.txt}
Change in overall progression rate by age \\
\ExpandableInput{tables/haq-lprog-diff-byage.txt}
\hline
\end{tabularx}
\scriptsize
Notes: 95\% confidence intervals are calculated using a normal distribution. Confidence intervals for changes in HAQ progression rates by age assume no covariance between the overall progression rate and the age-specific rates reported by \citet{michaud2011treatment}.
\end{threeparttable}
\end{center}
\end{table}

\subsubsection{Latent class growth model} \label{sec:haq-lcgm}
We also model the rate of HAQ progression using a mixture model approach that has increasingly been used to model HAQ progression over time \citep{stevenson2016adalimumab, norton2013trajectories, norton2014health}. These models suggest that different subgroups have distinct HAQ trajectories and that the rate of worsening of HAQ progression decreases over time. We use the LCGM estimated by \citet{norton2014health} and since we aim to model trajectories for cDMARDs and NBTs we chose the specification based on data from the Early Rheumatoid Arthritis Cohort Study (ERAS) cohort, which has a high percentage of patients receiving methotrexate and a very small percentage receiving biologics. Complete details of the LCGM are provided in \autoref{app:lcgm-haq}. 

<<haq_lcgm_probs, echo = FALSE, include = FALSE>>=
# latent class probabilities 
args <- formals(sample_pats)
rf <- .73
acr.criteria <- 1 
imdq <- 0.49
x <- c(1, args$age_mean, 0, args$das28_mean, 8.2, rf, acr.criteria, imdq)
indx.delta <- unlist(haq.lcgm.pars$index[c("delta2", "delta3", "delta4")])
delta <- matrix(haq.lcgm.pars$coef$coef[indx.delta], nrow = 3, byrow = TRUE)
probs <- mlogit_prob(x, delta)
@

The \citet{norton2014health} LCGM determined that there are four classes of patients and thus four distinct HAQ trajectories. The probability of class membership depends on 7 variables: age, gender, DAS28, disease duration, rheumatoid factor, the ACR 1987 criteria for RA, and a measure of socioeconomic status. Age, gender, and the DAS28 are relevant to the way the population is defined within our model (see \autoref{sec:populations}) and are therefore important determinants of the HAQ trajectory. Other variables (disease duration, rheumatoid factor, ACR criteria, and socioeconomic status) are not defined within our population. We consequently set disease duration (8.2 months), rheumatoid factor (0.73), and the socioeconomic status variable (0.49) equal to their mean values with the ERAS cohort. The ACR criteria was set to 1. 

HAQ trajectores (in levels) by class are shown \autoref{fig:lcgm-haq-prog}. The dotted lines plot observed mean values. There are clear distinguishable classes as both the level of the HAQ score and its slope vary between groups. \citet{norton2014health} refer to the groups as ``low'', ``moderate'', ``high'', and ``severe'' groups, in order from the lowest HAQ scores to the highest. The observed trends for the low, medium, and high groups follow a J-shaped pattern with a sharp drop following treatment initiation and an upward slope thereafter, while the severe group experiences persistently high HAQ scores. Since our model separates the initial treatment phase from the maintenance phase, we are only concerned with HAQ progression following the iniital drop. As in \citet{stevenson2016adalimumab}, we consequently only predict values from year 2 onward. The fitted values are the solid upward sloping lines in the plot.  
\begin{figure}[H]
\centering
\includegraphics[max size={.8\textwidth}{.8\textheight}]{../../data-raw/figs/haq-lcgm-obsexp.pdf}
\caption{Observed and predicted HAQ trajectories in the ERAS dataset from the latent class growth model}\label{fig:lcgm-haq-prog}
\end{figure}

<<haq_lcgm, echo = FALSE, include = FALSE>>=
# haq trajectories
t <- seq(2, 30)
xt <- 1 - (1/(1 + t))
haq_lcgm <- function(beta){
  return(beta[1] + beta[2] * xt + beta[3] * xt^2 + beta[4] * xt^3)
}
beta1 <- haq.lcgm.pars$coef[parameter == "beta1", coef]
beta2 <- haq.lcgm.pars$coef[parameter == "beta2", coef]
beta3 <- haq.lcgm.pars$coef[parameter == "beta3", coef]
beta4 <- haq.lcgm.pars$coef[parameter == "beta4", coef]
haq.lcgm1 <- haq_lcgm(beta1)
haq.lcgm2 <- haq_lcgm(beta2)
haq.lcgm3 <- haq_lcgm(beta3)
haq.lcgm4 <- haq_lcgm(beta4)
haq.lprog <- therapy.pars$haq.lprog[sname == "cdmards", est]
haq.dt <- data.table(t = t[-1], dhaq_lcgm1 = diff(haq.lcgm1), dhaq_lcgm2 = diff(haq.lcgm2),
                     dhaq_lcgm3 = diff(haq.lcgm3), dhaq_lcgm4 = diff(haq.lcgm4),
                     dhaq_lp1 = haq.lprog, dhaq_lp2 = haq.lprog,
                     dhaq_lp3 = haq.lprog, dhaq_lp4 = haq.lprog)

# plot
p.dat <- melt(haq.dt, id.vars = "t")
p.dat[, type := ifelse(grepl("dhaq_lp", variable) == TRUE, "Constant linear progression", "LCGM")]
p.dat[, class := ifelse(variable %in% c("dhaq_lcgm1", "dhaq_lp1"), "Class 1", NA)]
p.dat[, class := ifelse(variable %in% c("dhaq_lcgm2", "dhaq_lp2"), "Class 2", class)]
p.dat[, class := ifelse(variable %in% c("dhaq_lcgm3", "dhaq_lp3"), "Class 3", class)]
p.dat[, class := ifelse(variable %in% c("dhaq_lcgm4", "dhaq_lp4"), "Class 4", class)]
p <- ggplot(p.dat, aes(x = t, y = value, col = factor(type))) + geom_line() + geom_point(size = .75) +
  facet_wrap(~class) +  xlab("Follow-up in years") + ylab("Yearly change in HAQ") +  
  scale_color_discrete("") + theme(legend.position = "bottom")
ggsave("figs/haq-lcgm-vs-linear.png", p, height = 5, width = 7)
@

An important question for cost-effectiveness modeling in RA is how the rate of progression within each class in the LCGM compares to a constant linear trajectory. We examine this question in \autoref{fig:lcgm-vs-linear}, which compares yearly rates of changes in HAQ using the LCGM and with constant annual rates of change (\Sexpr{haq.lprog} per year) based on the \citet{wolfe2010loss} analysis. The LCGM was simulated over 30 years and differences between year $t$ and year $t-1$ were used to assess changes in HAQ score from one year to the next.  

\begin{figure}[H]
\centering
\includegraphics[max size={.7\textwidth}{.7\textheight}]{figs/haq-lcgm-vs-linear.png}
\caption{A comparison of predicted yearly changes in HAQ between a latent class growth model and constant linear progression from year 2 onwards}\label{fig:lcgm-vs-linear}
\end{figure}

In the moderate, high, and severe groups the rate of HAQ progression is higher initialy in the LCGM than in the \citet{wolfe2010loss} analysis; however, the LCGM modeled rate of HAQ progression declines over time and eventually begins to approach zero. In the low group, HAQ increases at a rate less than \Sexpr{haq.lprog} per year and the rate of increase declines over time. 

\subsection{HAQ trajectory with bDMARD maintenance treatment}
Based on the NDB longitudinal study, \citet{wolfe2010loss} estimated the overall annual HAQ progression rate among RA patients who had switched to biologic treatment at -0.001 (95CI: -0.004 to 0.002). In a separate analysis, also based on NDB data, \citet{michaud2011treatment} reported annual HAQ progression rates by treatment adjusted for baseline HAQ score, age, sex, education, smoking, BMI, comorbidity, and RA onset. The average HAQ rate among patients on a biologic was -0.001 as well, which instills confidence that the reported HAQ progression rates for different bDMARDs as reported by \citet{michaud2011treatment} can be directly compared with the overall annual HAQ progression rate of 0.031 reported by \citet{wolfe2010loss}. Accordingly, bDMARD specific HAQ progression rates by \citet{michaud2011treatment} are used in the model. For bDMARD treatments evaluated in the model for which no HAQ progression rate was reported by \citet{michaud2011treatment}, the overall biologic rate of -0.001 is used. 

\subsection{Duration of maintenance treatment}\label{duration-of-maintenance-treatment}
\subsubsection{CORRONA database}\label{sec:ttd-corrona}
Time to treatment discontinuation for patients on maintenance treatment for model structures \textbf{S1-S5} is based on analyses from the CORRONA database \citep{strand2013op0064}. The analysis sample consisted of 6,209 patients age 18 or older treated between 2002 and 2011 receiving either TNF inhibitors or other bDMARDs. The mean age was 57.6 years, 43\% of patients were biologic naive, the mean CDAI was 16, and just over 26\% of patients had high disease activity (CDAI $\geq$ 22). 

7 parametric survival models (exponential, Weibull, Gompertz, gamma, log-logistic, lognormal, and generalized gamma) were estimated on individual patient data reconstructed from a Kaplan-Meier curve from the CORRONA analysis using the algorithm developed in \citet{guyot2012enhanced}. We compared fit using the Akaike Information Criteria (AIK) and Bayesian Information Criteria (BIC) (\autoref{tbl:ic-ttd-corrona}). The generalized gamma had the lowest AIC and BIC, so we consider it to be the preferred model. A plot of of the generalized gamma distribution against the Kaplan-Meier curve is shown in \autoref{fig:corrona-gg}. As can be seen in the plot, the shape of the survival curve estimated using a generalized gamma distribution tracks the Kaplan-Meier curve closely.  

<<ipdsurv-corrona, echo = FALSE, resutls = 'tex'>>=
tab <- read.csv("../../data-raw/tables/ttd-corrona-ipdsurv-ic.csv")
tab <- cbind(as.matrix(tab[, 1]), formatC(as.matrix(tab[, -1]), format = "d", big.mark = ","))
tex <- print(xtable(tab), 
      include.rownames = FALSE, include.colnames = FALSE,
      only.contents = TRUE, sanitize.text.function = identity,
      file = "tables/ttd-corrona-ipdsurv-ic.txt")
@

\begin{table}[!ht]
\begin{center}
\begin{threeparttable}
\caption{AIC and BIC for parametric models of treatment duration from the CORRONA database} \label{tbl:ic-ttd-corrona}
\begin{tabularx}{\textwidth}{@{\extracolsep{\fill}}lcccc}
\hline
\multicolumn{1}{l}{Distribution} & \multicolumn{1}{c}{AIC} & \multicolumn{1}{c}{BIC}  \\
\hline
\ExpandableInput{tables/ttd-corrona-ipdsurv-ic.txt}
\hline
\end{tabularx}
\end{threeparttable}
\end{center}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[max size={.7\textwidth}{.7\textheight}]{../../data-raw/figs/ttd-corrona-ipdsurv-gengamma.pdf}
\caption{Generalized gamma and Kaplan-Meier time to treatment discontinuation curves using reconstructed individual patient data from the CORRONA database}\label{fig:corrona-gg}
\end{figure}

We considered estimating separate time to discontinuation curves for each therapy, but did not for a number of the reasons cited in \citet{stevenson2016adalimumab}. The majority of the literature focuses on anti-TNFs (e.g., infliximab, etanercept, and adalimumab) \citep[e.g.][]{gomez2006switching, yazici2009changing, pan2009comparison}, which makes it difficult to estimate discontinuation curves for the other therapies. Furthermore, studies comparing rates of discontinuation across therapies tend to be observational because clinical trials are of short duration and do not reflect real-world patient populations. However, although observational studies provide accurate predictions on time to discontinuation, it is difficult to avoid bias from confounding when estimating differences across treatments because patients are not randomized into treatment and control groups \citep{souto2015rate} .   

Unlike during the initial treatment phase, we do not condition rates of treatment discontinuation on the level of disease activity. The reason for this is that we could not find studies stratifying treatment duration curves by DAS28, SDAI, or CDAI. As a result, model structures \textbf{S1-S5} assume that conditional on continuing treatment beyond the first 6 months, duration does not depend on baseline disease activity, the change in disease activity from baseline, or whether the patient was biologic naive or experienced. 

We also lack data on treatment duration for patients on cDMARDs. Following \citet{stevenson2016adalimumab}, we assume that, conditional on continuing treatment at 6 months, treatment duration for bDMARDs is applicable to treatment duration for cDMARDs. This is, in turn, based on the assumption that cDMARDs are not likely to be more toxic than biologics used in combination with cDMARDs. 

\subsubsection{BSRBR database}\label{sec:ttd-bsrbr}
In model structure \textbf{S6}, we stratify our time to treatment discontinuation by EULAR response based on analyses of the British Society for Rheumatology Biologics Registers (BSRBR) database \citep{stevenson2016adalimumab}. As with the CORRONA based estimates, we fit 7 parametric survival models using individual patient data reconstructed from survival curves using the \citet{guyot2012enhanced} algorithm. We used the survival curves reported in \citet{stevenson2016adalimumab} to create the patient data. The Akaike Information Criteria (AIK) and Bayesian Information Criteria (BIC) of each model by EULAR response category (moderate, good) are shown in \autoref{tbl:ic-dur-eular}.

<<ipdsurv, echo = FALSE, resutls = 'tex'>>=
tab <- read.csv("../../data-raw/tables/ttd-bsrbr-ipdsurv-eular-ic.csv")
tab <- cbind(as.matrix(tab[, 1]), formatC(as.matrix(tab[, -1]), format = "d", big.mark = ","))
# colnames(tab) <- c("Distribution", "AIC (moderate)", "BIC (moderate)", "AIC (good)", "BIC (good)")
# ptab <- pandoc.table(tab)
tex <- print(xtable(tab), 
      include.rownames = FALSE, include.colnames = FALSE,
      only.contents = TRUE, sanitize.text.function = identity,
      file = "tables/ttd-bsrbr-ipdsurv-eular-ic.txt")
@

\begin{table}[!ht]
\begin{center}
\begin{threeparttable}
\caption{AIC and BIC for parametric models of treatment duration by EULAR response} \label{tbl:ic-dur-eular}
\begin{tabularx}{\textwidth}{@{\extracolsep{\fill}}lcccc}
\hline
\multicolumn{1}{l}{} & \multicolumn{2}{c}{Moderate EULAR response} & \multicolumn{2}{c}{Good EULAR response} \\
\cmidrule{2-3} \cmidrule{4-5}
\multicolumn{1}{l}{Distribution} & \multicolumn{1}{c}{AIC} & \multicolumn{1}{c}{BIC} & \multicolumn{1}{c}{AIC}  & \multicolumn{1}{c}{BIC}   \\
\hline
\ExpandableInput{tables/ttd-bsrbr-ipdsurv-eular-ic.txt}
\hline
\end{tabularx}
\end{threeparttable}
\end{center}
\end{table}

One concern is that the BSRBR is representative of the UK but not the US. As a result, we also estimate ``adjusted'' survival models appropriate for US based analyses. The adjustment is made in six steps using the analyses from the CORRONA database described in \autoref{sec:ttd-corrona}. 

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item Calculate a hazard function based on a survival curve from an analysis
  of the CORRONA database. In particular, reconstruct individual patient
  data from the survival curve \citet{guyot2012enhanced} and fit a
  spline-based survival model. Then use the spline-based model to
  estimate the hazard function $h(t)_{corrona}$.
\item Calculate a hazard function based on the BSRBR. To do so, first
  calculate hazard functions for both moderate and good EULAR responders
  using the same method described in step 1. Then calculate an overall
  hazard function with the proportion of moderate and good responders in
  the BSRBR analysis. Given that the number of moderate responders is
  \(5,492\) and the number of good responders is $2,417$ the overall
  hazard function is $h(t)_{bsrbr} = \frac{5,492}{7,909}h(t)_{bsrbr, moderate} + \frac{2,417}{7,909}h(t)_{bbsrbr, good}$.
\item At each point in time, calculate the ratio of the CORRONA and BSRBR
  hazard functions: $HR(t) = h(t)_{corrona}/h(t)_{bbsrbr}$.
\item Apply the hazard ratio in step 3 to the BSRBR hazard functions for
  each EULAR response category. That is $h(t)_{bsrbr, moderate, adj} = h(t)_{bsrbr, moderate} \cdot HR(t)$ and $h(t)_{bsrbr, good, adj} = h(t)_{bsrbr, good} \cdot HR(t)$.
\item Generate survival curves using the hazard functions from step 4.
  Specifically, given a general hazard function $h(t)$, calculate the
  cumulative hazard functions, $H(t) = \int_{z = 0}^{t} h(z)dz$,
  convert this to a survival function using $S(t) = exp(-H(t))$, and
  reconstruct individual patient data using the survival curve.
\item Fit parametric survival models to the individual patient data
  generated in step 5.
\end{enumerate}

Both adjusted and unadjusted survival curves by EULAR response fit using a generalized gamma distribution are shown in \autoref{fig:bsrbr-gg}. AIC and BIC for the parametric models fit in step 6 do the adjusted individual patient data are shown in \autoref{tbl:ic-dur-adj-eular}.

\begin{figure}
\centering
\includegraphics[max size={\textwidth}{\textheight}]{../../data-raw/figs/ttd-bsrbr-ipdsurv-comp-gengamma-by-eular.pdf}
\caption{Generalized gamma survival curve of treatment duration using
reconstructed individual patient data based on analyses from Stevenson
et al. (2016) by EULAR response category}\label{fig:bsrbr-gg}
\end{figure}

<<bsrbr-eular-surv, echo = FALSE>>=
tab <- read.csv("../../data-raw/tables/ttd-bsrbr-ipdsurv-eular-adjusted-ic.csv")
tab <- cbind(as.matrix(tab[, 1]), formatC(as.matrix(tab[, -1]), format = "d", big.mark = ","))
# colnames(tab) <- c("Distribution", "AIC (moderate)", "BIC (moderate)", "AIC (good)", "BIC (good)")
# ptab <- pandoc.table(tab)
tex <- print(xtable(tab), 
      include.rownames = FALSE, include.colnames = FALSE,
      only.contents = TRUE, sanitize.text.function = identity,
      file = "tables/ttd-bsrbr-ipdsurv-eular-adjusted-ic.txt")
@

\begin{table}[!ht]
\begin{center}
\begin{threeparttable}
\caption{AIC and BIC for CORRONA adjusted parametric models of treatment duration by EULAR response} \label{tbl:ic-dur-adj-eular}
\begin{tabularx}{\textwidth}{@{\extracolsep{\fill}}lcccc}
\hline
\multicolumn{1}{l}{} & \multicolumn{2}{c}{Moderate EULAR response} & \multicolumn{2}{c}{Good EULAR response} \\
\cmidrule{2-3} \cmidrule{4-5}
\multicolumn{1}{l}{Distribution} & \multicolumn{1}{c}{AIC} & \multicolumn{1}{c}{BIC} & \multicolumn{1}{c}{AIC}  & \multicolumn{1}{c}{BIC}   \\
\hline
\ExpandableInput{tables/ttd-bsrbr-ipdsurv-eular-adjusted-ic.txt}
\hline
\end{tabularx}
\end{threeparttable}
\end{center}
\end{table}

\subsection{Rebound post treatment}
Since no data exists on the size of the HAQ rebound post treatment, we vary its size as a proportion of the initial 6-month HAQ decline. 1 is used as an upper bound, which implies that the HAQ rebound is equal to the improvement experienced at the end of the initial 6-month period with that treatment. 0.5 is used as a lower bound based on expert opinion.

\subsection{Serious infections}
Based on the NMA by \citet{singh2011adverse} and in accordance with \citet{stevenson2016adalimumab}, we assume a rate of 0.035 (95\% CI: 0.027 to 0.046) infections per person-year with all bDMARDs and a rate of 0.026 (no CI reported) infections per person-year with cDMARDs. The rate of infection is assumed to be equal across bDMARDs because the published results for specific bDMARDs are estimated with very little precision. The standard error on the infection rate for bDMARDs is assumed to be the same as the standard error for cDMARDs since no standard error was reported for bDMARDs in \citet{singh2011adverse}.

<<si, echo = FALSE, include = FALSE, cache = TRUE>>=
set.seed(100)
pat <- sample_pats(n = 1000)
input.dat <- input_data(patdata = pat)
parsamp <- sample_pars(n = 1000)
arm.snames <- c("cdmards", "adamtx")
arminds <- as.list(which(therapy.pars$info$sname %in% arm.snames))
arm.names <- c("cDMARDs or NBT", "bDMARDs")
dur.dist <- c("exponential", "weibull", "gompertz", "gamma", "llogis", "lnorm", "gengamma")
dur.dist.l <- c("Exponential", "Weibull", "Gompertz", "Gamma", "Log-logistic", "Lognormal",
                   "Generalized gamma")
sim6 <- vector(length(dur.dist) * length(arminds), mode = "list")
counter <- 1
for (i in 1:length(arminds)){
  for(j in 1:length(dur.dist)){
    sim6[[counter]] <- sim_haq(arminds[[i]], input_data = input.dat, pars = parsamp,
                               max_months = 6, dur_dist = dur.dist[i])
    sim6[[counter]][, dur_dist := dur.dist.l[j]]
    sim6[[counter]][, arm := arm.names[i]]
    counter <- counter + 1
  }
}
sim6 <- rbindlist(sim6)
sim6[, si_ever := ifelse(ttsi <= ttd, 1, 0)]
si.prop <- sim6[, .(si = mean(si_ever)), by = c("dur_dist", "arm", "sim")]
si.prop <- si.prop[, .(si_mean = mean(si), si_lower = quantile(si, .025),
                       si_upper = quantile(si, .974)), by = c("dur_dist", "arm")]

# tables comparing serious infection rates by drugs
si1.mtx <- si.prop[dur_dist == "Generalized gamma" & arm == "cDMARDs or NBT",
                   si_mean]
si1.bio <- si.prop[dur_dist == "Generalized gamma" & arm == "bDMARDs",
                   si_mean]
tab1 <- si.prop[dur_dist == "Generalized gamma", .(arm, si_mean, si_lower, si_upper)]
tab1[, si_mean := formatC(si_mean, format = "f", digits = 4)]
tab1[, si_lower := formatC(si_lower, format = "f", digits = 4)]
tab1[, si_upper := formatC(si_upper, format = "f", digits = 4)]
tex <- print(xtable(tab1),
      include.rownames = FALSE, include.colnames = FALSE,
      only.contents = TRUE, sanitize.text.function = identity,
      file = "tables/si-prop-gengamma.txt")

# tables comparing serious infection by distribution
tab2 <- si.prop[arm == arm.names[1], .(dur_dist, si_mean)]
tab2[, si_mean := formatC(si_mean, format = "f", digits = 4)]
tex <- print(xtable(tab2),
      include.rownames = FALSE, include.colnames = FALSE,
      only.contents = TRUE, sanitize.text.function = identity,
      file = "tables/si-prop-mtx-bydist.txt")
@

\begin{table}[!ht]
\begin{center}
\begin{threeparttable}
\caption{Probability of serious infection} \label{tbl:si-prob}
\begin{tabularx}{\textwidth}{@{\extracolsep{\fill}}lrrr}
\hline
\multicolumn{1}{l}{} & \multicolumn{3}{c}{Probability} \\
\cmidrule{2-4} 
\multicolumn{2}{l}{} & \multicolumn{2}{c}{95\% CI} \\
\cmidrule{3-4} 
\multicolumn{1}{c}{} & \multicolumn{1}{c}{Mean} & \multicolumn{1}{c}{Lower} & \multicolumn{1}{c}{Upper} \\
\hline
\ExpandableInput{tables/si-prop-gengamma.txt}
\hline
\end{tabularx}
\scriptsize
Notes: Probabilities are estimated by simulating 1,000 patients and 1,000 parameter sets. Treatment duration is simulated using a generalized gamma distribution. 
\end{threeparttable}
\end{center}
\end{table}

A patient in the IPS has a serious infection if a serious infection occurs before the simulated time of treatment discontinuation. \autoref{tbl:si-prob} shows the probability of this occuring when treatment duration is modeled using a generalized gamma distribution. The probability of a serious infection is relatively rare as only \Sexpr{formatC(si1.mtx, format = "f", digits = 2)} of patient on cDMARDs and \Sexpr{formatC(si1.bio, format = "f", digits = 2)} using bDMARDs have serious infections. However, differences between cDMARDs and bDMARDs are not insignificant as the probability of a serious infection is almost \Sexpr{formatC(100*(si1.bio - si1.mtx), format = "f", digits = 0)} percentage points higher with bDMARDs than with cDMARDs.

\begin{table}[!ht]
\begin{center}
\begin{threeparttable}
\caption{Probability of serious infection with cDMARDs by distribution used to model treatment duration} \label{tbl:si-prop-bydist}
\begin{tabularx}{.5\textwidth}{l@{\extracolsep{\fill}}r}
\hline
\multicolumn{1}{c}{Distribution} & \multicolumn{1}{c}{Mean probability} \\
\hline
\ExpandableInput{tables/si-prop-mtx-bydist.txt}
\hline
\end{tabularx}
\scriptsize
Notes: Probabilities are estimated by simulating 1,000 patients and 1,000 parameter sets. 
\end{threeparttable}
\end{center}
\end{table}

An important question related to the sensitivity of results to the model specification is whether the probability of serious infections depends on the distribution used to model time to treatment discontinuation. \autoref{tbl:si-prop-bydist} consequently comparies serious infection probabilities by the distribution used to simulate treatment duration. There are very small differences across distributions, suggesting that the treatment duration distribution has almost no impact on the probability of serious infections.  

\FloatBarrier

\subsection{Utility}\label{utility}
Two algorithms can be used to map HAQ to an EQ-5D utility score. Each is used to simulate utility for every patient in the model to obtain a distribution of utility over time. Our preferred algorithm is the mixture model developed by \citet{alava2013relationship}, which is described in detail in \autoref{app:sim-utility-mixture}. The second algorithm uses the logistic regression equation reported in \citet{wailoo2006modeling}. The regression coefficients are shown in \autoref{tbl:util-wailoo-coef} and are used to predict utility with the inverse logit function (see \autoref{app:logistic-regression}).

<<util-wailoo-pars, echo = FALSE, include = FALSE>>=
tab <- data.frame(coef = util.wailoo.pars$coef,
                  se = util.wailoo.pars$se)
tab <- formatC(as.matrix(tab), format = "f")
rownames(tab) <- c("Intercept", "Age", "Disease duration", "Baseline HAQ",
                   "Male", "Number of previous DMARDs", "Current HAQ")
tex <- print(xtable(tab), 
      include.rownames = TRUE, include.colnames = FALSE,
      only.contents = TRUE, sanitize.text.function = identity,
      file = "tables/util-wailoo-pars.txt")
@

\begin{table}[!ht]
\begin{center}
\begin{threeparttable}
\caption{Logistic regression coefficient from Wailoo utility algorithm} \label{tbl:util-wailoo-coef}
\begin{tabularx}{\textwidth}{@{\extracolsep{\fill}}lcc}
\hline
\multicolumn{1}{c}{} & \multicolumn{1}{c}{Estimate} & \multicolumn{1}{c}{Standard error}  \\
\hline
\ExpandableInput{tables/util-wailoo-pars.txt}
\hline
\end{tabularx}
\scriptsize
Notes: Coefficients are from the logistic regression reported in \citet{wailoo2006modeling}. 
\end{threeparttable}
\end{center}
\end{table}

\autoref{fig:util-comparison} compares results from the two algorithms. Mean utility scores from the \citet{alava2013relationship} mixture model lie above those from the \citet{wailoo2006modeling} equation for all values of HAQ. Moreover, the slope of utility curve produced from the mixture model is steeper (although less so for the commonly observed HAQ scores between 1 and 1.5), implying that changes in HAQ from the mixture model predict larger changes in utility. Given that the mixture models have been shown to predict utility more accurately \citep{alava2012tails, alava2013relationship, hernandez2014comparison}, this suggests that standard models underestimate the quality-adjusted life-year benefits, and hence, the cost-effectiveness of treatments. 

<<utility, echo = FALSE, include = FALSE, cache = TRUE>>=
n <- 1000
pat <- sample_pats(n = n)
input.dat <- input_data(patdata = pat)
haq = seq(0, 3, .1)
simhaq <- data.table(id = 1, sim = rep(seq(1, n), each = length(haq)), haq = rep(haq, n), age = 55)
parsamp <- sample_pars(n = n)
util.mix <- sim_utility_mixture(simhaq, pat[, "male"],  pars = c(pain, parsamp$mixture.utility))$utility
util.wailoo <- sim_utility_wailoo(simhaq, input.dat, parsamp$wailoo.utility)
util.dt <- data.table(util = c(util.mix, util.wailoo), haq = rep(simhaq$haq, 2),
                      lab = c(rep("Alava (2013) mixture model", nrow(simhaq)),
                              rep("Wailoo (2006)", nrow(simhaq))))
util.dt <- util.dt[, .(mean_util = mean(util)), by = c("haq", "lab")]
p <- ggplot(util.dt, aes(x = haq, y = mean_util, col = lab)) + geom_line() + xlab("HAQ") + ylab("Mean utility") +
  scale_colour_discrete("") + theme(legend.position = "bottom")
ggsave("figs/util-byhaq-comparison.png", p, height = 5, width = 7)
@

\begin{figure}
\centering
\includegraphics[max size={.8\textwidth}{.8\textheight}]{figs/util-byhaq-comparison.png}
\caption{Simulated mean utility by current
HAQ}\label{fig:util-comparison}
\end{figure}

The utility score depends on two other factors in addition to HAQ. First, disutility due to serious infections is assumed to be 0.156 for the duration of the month of infection based on prior studies \citep{stevenson2016adalimumab, oppong2013impact}. However, given the weak evidence for this estimate, the disutility of an infection is allowed to vary by 20\% in either direction. Second, patient preferences for treatment unrelated to efficacy or serious infections (e.g., preferences for treatment attributes) can have a direct effect on utility. Given the limited evidence, we currently assume that this effect is 0, but have programmed the model so that preferences for treatment can easily be incorporated into the model if new evidence emerges.

\subsection{Mortality}
The probability of death is simulated as a function of age/sex specific mortality from U.S. lifetables \citep{arias2015united}, baseline HAQ, and changes in HAQ from baseline. \citet{wolfe2003predicting} estimate an odds ratio for the effect of HAQ on mortality of 2.22, which is applied to the absolute mortality rates of the general population (HAQ score of 0). To capture the effect of treatment on mortality, we assume that, for every 0.25-unit increase in HAQ score, subsequent 6-month mortality increases according to the hazard ratios reported in \citet{michaud2012mortality}. Parameter estimates are shown in \autoref{tbl:mortpars}.

<<mortpars, echo = FALSE, include = FALSE>>=
# odds ratio baseline haq
tab1 <- mort.or[, .(logor, logor_lower, logor_upper)]
tab1 <- formatC(as.matrix(tab1), format = "f", digits = 3)
tab1 <- cbind("\\hspace{3mm}Log odds of mortality", tab1, "\\citet{wolfe2003predicting}")
tex1 <- print(xtable(tab1), 
      include.rownames = FALSE, include.colnames = FALSE,
      only.contents = TRUE, sanitize.text.function = identity, hline.after = NULL,
      file = "tables/mort-or.txt")

# hazard ratio change in haqq
tab2 <- mort.hr.haqdif[, .(loghr, loghr_lower, loghr_upper)]
tab2 <- formatC(as.matrix(tab2), format = "f", digits = 3)
tab2.names <- paste0("\\hspace{3mm}Log hazard ratio ", c("0-6 months", ">6-12 months", ">12-24 months",
                                           ">24-36 months", ">36 months"))
tab2 <- cbind(tab2.names, tab2, "\\citet{michaud2012mortality}")
tex2 <- print(xtable(tab2), 
      include.rownames = FALSE, include.colnames = FALSE,
      only.contents = TRUE, sanitize.text.function = identity, hline.after = NULL,
      file = "tables/mort-hr-haqdif.txt")
@

\begin{table}[!ht]
\begin{center}
\begin{threeparttable}
\caption{Mortality parameters} \label{tbl:mortpars}
\footnotesize
\begin{tabularx}{\textwidth}{@{\extracolsep{\fill}}lcccc}
\hline
\multicolumn{2}{l}{} & \multicolumn{2}{c}{95\% CI} & \multicolumn{1}{l}{} \\
\cmidrule{3-4} 
\multicolumn{1}{l}{} & \multicolumn{1}{l}{Estimate} & \multicolumn{1}{c}{Lower} & \multicolumn{1}{c}{Upper} & \multicolumn{1}{c}{Reference} \\
\hline
Impact of baseline HAQ on mortality \\
\ExpandableInput{tables/mort-or.txt}
Impact of change in HAQ from baseline on mortality\\
\ExpandableInput{tables/mort-hr-haqdif.txt}
\hline
\end{tabularx}
\scriptsize
Notes: 95\% confidence intervals are calculated using normal distributions on the log odds
and log hazard ratio scales. 
\end{threeparttable}
\end{center}
\end{table}

<<survplot, echo = FALSE, include = FALSE, cache = TRUE>>=
set.seed(100)
n <- 1000; age <- 55; haq0 <- 1; cycle.len <- 6; max.age <- 100
t <- seq(0, 12/cycle.len * (max.age - age) - 1)
haq.ts0 <- rep(0, length(t))
haq.ts1 <- pmin(haq0 + 0 * t, 3)
haq.ts2 <- pmin(haq0 + .03 * t, 3)
surv <- c(sim_survtime(n = n, haq = haq.ts0, male = 0),
          sim_survtime(n = n, haq = haq.ts0, male = 1),
          sim_survtime(n = n, haq = haq.ts1, male = 0),
          sim_survtime(n = n, haq = haq.ts1, male = 1),
          sim_survtime(n = n, haq = haq.ts2, male = 0),
          sim_survtime(n = n, haq = haq.ts2, male = 1))
lab <- c(rep("No RA", 2 * n),
         rep("Constant HAQ", 2 * n),
         rep("HAQ increase of 0.03 per year", 2 * n))
gender <- rep(rep(c("Female", "Male"), each = n), 3)
surv <- data.table(surv = surv, lab = lab, gender = gender)
surv[, ecdf := ecdf(surv)(surv), by = c("lab", "gender")]
surv.mean.nora <- mean(surv[gender == "Female" & lab == "No RA", surv])
surv.mean.chaq <- mean(surv[gender == "Female" & lab == "Constant HAQ", surv])
surv.mean.lhaq <- mean(surv[gender == "Female" & lab == "HAQ increase of .03 per year", surv])
surv.mean.nora.m <- mean(surv[gender == "Male" & lab == "No RA", surv])
surv.mean.chaq.m <- mean(surv[gender == "Male" & lab == "Constant HAQ", surv])
surv.mean.lhaq.m <- mean(surv[gender == "Male" & lab == "HAQ increase of .03 per year", surv])
p <- ggplot(surv, aes(x = surv, y = 1 - ecdf, col = lab)) + geom_line() + xlab("Age") + ylab("Proportion surviving") + facet_wrap(~gender) +
  scale_colour_discrete("") + theme(legend.position = "bottom")
ggsave("figs/surv.png", p, width = 7, height = 5)
@

\autoref{fig:surv} plots survival curves by gender for $1,000$ patients with a baseline age 55. Survival was simulated by setting the log odds ratios and log hazard ratios from {tbl:mortpars} equal to their point estimates. Three scenarios are considerd. In scenario one, patients do not have rheumatoid arthritis (i.e., HAQ score of 0). In the second scenario patients have baseline HAQ score of 1 but it does not increase over time. In the third scenario, patients still have a baseline HAQ score of 1 but it increases by 0.03 per year. The third scenario therefore utilizes the relationship between changes and HAQ and mortality from \citet{michaud2012mortality} while the second scenario does not. 

Mean survival for females without RA was \Sexpr{formatC(surv.mean.nora, format = "f", digits = 1)} years and declined to \Sexpr{formatC(surv.mean.chaq, format = "f", digits = 1)} for females with a constant baseline HAQ of 1 and to \Sexpr{formatC(surv.mean.lhaq, format = "f", digits = 1)} when HAQ increased by 0.03 per year. Mean survival for males in the first, second, and third scenario were \Sexpr{formatC(surv.mean.nora.m, format = "f", digits = 1)}, \Sexpr{formatC(surv.mean.chaq.m, format = "f", digits = 1)}, and \Sexpr{formatC(surv.mean.lhaq.m, format = "f", digits = 1)} years respectively. Overall, the figure suggests that RA increases mortality and that larger increases in HAQ over time increase mortality by even more.

\begin{figure}[H]
\centering
\includegraphics[max size={.7\textwidth}{.7\textheight}]{figs/surv.png}
\caption{Simulated survival curve for a patient age 55}\label{fig:surv}
\begin{minipage}{\linewidth}
\footnotesize
Notes: Baseline HAQ is 1 for the ``Constant HAQ'' and ``HAQ increase of 0.03 per year'' scenarios; baseline HAQ is 0 for the ``No RA'' scenario.
\end{minipage}
\end{figure}

\FloatBarrier

\subsection{Cost}\label{cost}
<<treat_cost, echo = FALSE, include = FALSE>>=
set.seed(100)

# cost for non-weight based dosing
tab = copy(therapy.pars$cost)
tab[, init_cost := init_dose_val/strength_val * init_num_doses * wac_per_unit + init_num_doses * infusion_cost]
tab[, ann_cost := ann_dose_val/strength_val * ann_num_doses * wac_per_unit + ann_num_doses * infusion_cost]

# cost for weight based dosing
wt <- sample_pats(1000)[, "weight"]
male.prop <- formals(sample_pats)$male_prop * 100
wtmale <- formals(sample_pats)$wtmale
wtfemale <- formals(sample_pats)$wtfemale
ifx <- tab[sname == "ifx"]
init.cost.ifx <- mean(ceiling(wt * ifx$init_dose_val / ifx$strength_val) * ifx$init_num_doses * ifx$wac_per_unit + ifx$init_num_doses * ifx$infusion_cost)
ann.cost.ifx <- mean(ceiling(wt * ifx$ann_dose_val / ifx$strength_val) * ifx$ann_num_doses * ifx$wac_per_unit + ifx$ann_num_doses * ifx$infusion_cost) 
tab[sname == "ifx", init_cost := init.cost.ifx]
tab[sname == "ifx", ann_cost := ann.cost.ifx]

# formatting
tab1 <- tab[, .(name, dosage, strength_dosage_form)]
tab2 <- tab[, .(init_num_doses, ann_num_doses, wac_per_unit, infusion_cost, 
                              init_cost, ann_cost)]
tab2f <- matrix(NA, nrow = nrow(tab2), ncol = ncol(tab2))
for (i in 1:ncol(tab2)){
  if (names(tab2)[i] == "wac_per_unit"){
      tab2f[, i] <- formatC(tab2[[i]], format = "f", digits = 2, big.mark = ",")
  } else{
      tab2f[, i] <- formatC(tab2[[i]], format = "d", big.mark = ",") 
  }
}
tab <- cbind(tab1, tab2f)
tab[, name := first_upper(name)]
tex <- print(xtable(tab), 
      include.rownames = FALSE, include.colnames = FALSE,
      only.contents = TRUE, sanitize.text.function = identity, hline.after = NULL,
      file = "tables/treat-cost.txt")
@

An overview of drug acquisition and administration costs is presented in \autoref{tbl:treat-cost}. Costs are a function of dose and frequency of administration, strength and dosage form, the wholesale acquisition cost (WAC), and infusion costs. Since infliximab dosing depend on patient weight, the costs for infliximab reported in the table average over a patient population that is \Sexpr{male.prop}\% male. The WACs in the table do not include discounts or rebates so they may be higher than actual drug costs.

\begin{landscape}
\begin{table}[H]
\begin{center}
\begin{threeparttable}
\caption{Drug acquisition and administration cost} \label{tbl:treat-cost}
\scriptsize
\begin{tabular}{lp{0.15\linewidth}p{0.15\linewidth}rrrrrr}
\hline
\multicolumn{1}{l}{Drug} &
\multicolumn{1}{p{0.15\linewidth}}{Dose and frequency of administration} & 
\multicolumn{1}{p{0.15\linewidth}}{Strength and dosage form} & 
\multicolumn{1}{p{0.08\linewidth}}{Number of doses first 6 months}  & 
\multicolumn{1}{p{0.08\linewidth}}{Number of dosees per year beyond the first 6 months} & 
\multicolumn{1}{c}{WAC per unit} & \multicolumn{1}{c}{Infusion cost} & 
\multicolumn{1}{p{0.08\linewidth}}{Cost for the first 6 months} &
\multicolumn{1}{p{0.08\linewidth}}{Cost per year beyond the first 6 months}\\
\hline
\ExpandableInput{tables/treat-cost.txt}
\hline
\end{tabular}
\tiny
Notes: Costs do not include rebates or discounts. Cost for infliximab are calculated by assuming that \Sexpr{male.prop}\% of patients are male and that the weight of men and women are \Sexpr{wtmale} kg and \Sexpr{wtfemale} kg respectively. Tocilizumab is dosed weekly if weight is greater than 100 kg; costs for tocilizumab reported in the table are for patients weighing less than 100 kg. IV = intravenous; SC = subcutaneous; WAC = whoesale acqusition cost. 
\end{threeparttable}
\end{center}
\end{table}
\end{landscape}

Parameters associated with resource use are showin in \autoref{tbl:resource-use-pars}. Costs related to physician visits, chest X-rays, tuberculosis tests, and outpatient follow-up are based on \citet{claxton2016economic}. The cost per hospital day and the relationship between the HAQ score and the annual number of hospital days are from \citet{carlson2015economic}. Cost of any serious infection are assumed to be equal to the cost of pneumonia hospitalization at \$5,873, based on Medicare reimbursement rates. \citet{wolfe2005household} provide an estimate of annual income loss in relation to HAQ scores: \$4,372 (95\% CI: 2,078 to 6,607; 2002 dollars) change per unit HAQ change, which are inflated to 2016 dollars.

<<resource_cost, echo = FALSE, include = FALSE>>=
# hospital days by HAQ
tab1 <- data.table(mean = eval(formals(sample_pars)$hosp_days_mean),
                   se = eval(formals(sample_pars)$hosp_days_se))
quant1 <- mom_gamma(tab1$mean, tab1$se, quant = c(.025, .975))
tab1[, lower := quant1$q0.025]
tab1[, upper := quant1$q0.975]
tab1[, se := NULL]
tab1 <- formatC(as.matrix(tab1), format = "f", digits = 3)
tab1.names <- paste0("\\hspace{3mm}HAQ: ", c("0-<0.5", "0.5-<1", "1-<1.5", "1.5-<2", "2-<2.5",
                                ">2.5"))
tab1 <- cbind(tab1.names, tab1, "\\citet{carlson2015economic}")
tex1 <- print(xtable(tab1), 
      include.rownames = FALSE, include.colnames = FALSE,
      only.contents = TRUE, sanitize.text.function = identity, hline.after = NULL,
      file = "tables/hosp-days-haq.txt")

# hospital cost per day in hospital
tab2 <- data.table(mean = eval(formals(sample_pars)$hosp_cost_mean)[1],
                   se = eval(formals(sample_pars)$hosp_cost_se)[1])
quant2 <- mom_gamma(tab2$mean, tab2$se, quant = c(.025, .975))
tab2[, lower := quant2$q0.025]
tab2[, upper := quant2$q0.975]
tab2[, se := NULL]
tab2 <- formatC(as.matrix(tab2), format = "d", big.mark = ",")
tab2 <- cbind("Cost per day in hospital", tab2, "\\citet{carlson2015economic}")
tex2 <- print(xtable(tab2), 
      include.rownames = FALSE, include.colnames = FALSE,
      only.contents = TRUE, sanitize.text.function = identity, hline.after = NULL,
      file = "tables/hosp-cost-perday.txt")

# General management cost
tab3 <- mgmt.cost[, .(est, lower, upper)]
tab3 <- formatC(as.matrix(tab3), format = "d", big.mark = ",")
tab3.names <- paste0("\\hspace{3mm}", c("Chest x-ray", "X-ray visit", "Outpatient follow-up", "Mantoux tuberculin skin test"))
tab3 <- cbind(tab3.names, tab3, "\\citet{claxton2016economic}")
tex3 <- print(xtable(tab3), 
      include.rownames = FALSE, include.colnames = FALSE,
      only.contents = TRUE, sanitize.text.function = identity, hline.after = NULL,
      file = "tables/mgmt-cost.txt")

# productivity loss
tab4 <- data.table(mean = eval(formals(sample_pars)$pl_mean),
                   se = eval(formals(sample_pars)$pl_se))
tab4[, lower := mean - qnorm(.975) * se]
tab4[, upper := mean + qnorm(.975) * se]
tab4 <- formatC(as.matrix(tab4[, .(mean, lower, upper)]), format = "d", big.mark = ",")
tab4 <- cbind("\\hspace{3mm}Linear regression coefficient - HAQ", tab4, "\\citet{wolfe2005household}")
tex4 <- print(xtable(tab4), 
      include.rownames = FALSE, include.colnames = FALSE,
      only.contents = TRUE, sanitize.text.function = identity, hline.after = NULL,
      file = "tables/prod-loss.txt")
@

\begin{table}[H]
\begin{center}
\begin{threeparttable}
\caption{Resource use parameters} \label{tbl:resource-use-pars}
\footnotesize
\begin{tabularx}{\textwidth}{@{\extracolsep{\fill}}lcccc}
\hline
\multicolumn{2}{l}{} & \multicolumn{2}{c}{95\% CI} & \multicolumn{1}{l}{} \\
\cmidrule{3-4} 
\multicolumn{1}{l}{} & \multicolumn{1}{l}{Estimate} & \multicolumn{1}{c}{Lower} & \multicolumn{1}{c}{Upper} & \multicolumn{1}{c}{Reference} \\
\hline
Days in hospital per year \\
\ExpandableInput{tables/hosp-days-haq.txt}
\ExpandableInput{tables/hosp-cost-perday.txt}
General management cost \\
\ExpandableInput{tables/mgmt-cost.txt}
Productivity loss \\
\ExpandableInput{tables/prod-loss.txt}
\hline
\end{tabularx}
\scriptsize
Notes: 95\% confidence intervals for hospital days per year by HAQ score and hospital cost per day are calculated by using the methods of moments to generate the parameters of the gamma distribution given a mean and standard error. The 95\% confidence intervals for general management costs are based on normal distributions as assumed in \citet{claxton2016economic}. 95\% confidence interval for productivity loss are calculated using a normal distribution and inflated to 2016 dollars. 
\end{threeparttable}
\end{center}
\end{table}

\section{Simulation and uncertainty analysis}\label{sec:sim-uncertainty}

\subsection{Individual patient simulation}\label{individual-patient-simulation}

The IPS is a discrete-time simulation that simulates individual patients one at a time. Model cycle, denoted by $t$, were chosen to be 6-months long to be consistent with most RCT and real-world data evidence. \autoref{alg:IPS} describes the main components of the IPS for a single patient and a given treatment in a treatment sequence. The full simulation cycles through each treatment in a sequence and through each simulated patient.

\begin{algorithm}
\caption{Main components of the individual patient simulation}
\label{alg:IPS}
\begin{enumerate}
\item \textbf{Initial treatment effect ($t = 0$)}
\begin{enumerate}
\item Simulate clinical response (SDAI or EULAR), time to serious infection $T_{si}$, and death.
\begin{enumerate}
\item \textbf{If} no clinical response, \textbf{then} stop treatment. Treatment switch caused by a serious infection if time to serious infection occured during cycle 0 (i.e. $T_{si} = 0$). Change in HAQ is assumed to be $0$. 
\newline \textbf{Else if} clinical response, \textbf{then} continue treatment. Simulate change in HAQ and time to treatment discontinuation $T$.
\item \textbf{If} patient died, \textbf{then} move to next patient. 
\end{enumerate}
\end{enumerate}
\item \textbf{Maintenance phase} (for $t > 0 \text{ and } t \leq T$)
\begin{enumerate}
\item Simulate death (see \autoref{ssec:simulating-death}) and change in HAQ.
\item \textbf{If} patient died, \textbf{then} move to next patient.
\item \textbf{If} $t = T$, \textbf{then} switch treatment. Treatment switch caused by a serious infection if time to serious infection occured during or before cycle T (i.e. $T_{si} \leq T$). 
\end{enumerate}
\end{enumerate}
\end{algorithm}

\subsection{Parameter uncertainty}\label{parameter-uncertainty}
Parameter uncertainty is quantified using PSA, which propagates uncertainty in the model input parameters throughout the model by randomly sampling the input parameters from their joint probability distribution \citep{baio2015probabilistic, claxton2005probabilistic}. Probability distributions are determined according to the distributional properties of the statistical estimates, which, in turn, depend on the statistical techniques used and the distributions of the underlying data. We, for the most part, use normal distributions for sample means, gamma distributions for right-skewed data (e.g., hospital costs), and Dirichlet distributions for multinomial data. The multivariate normal distribution is used for regression parameters estimated using frequentist techniques, provided that the variance-covariance from the statistical analysis is available. For parameters estimated using a Bayesian statistical model, we use the posterior distribution generated from the Markov-Chain Monte-Carlo (MCMC) algorithm. When we lack evidence on a parameter, we typically assume a uniform distribution with lower and upper limits that reflect the degree of uncertainty in the parameter. The PSA parameter distributions are summarized in \autoref{tbl:psa-dists}. 

\begin{table}[!ht] 
\begin{center}
\begin{threeparttable}
\caption{Probabilistic Sensitivity Analysis Parameter Distributions} \label{tbl:psa-dists}
\def\arraystretch{1.5}
\begin{tabularx}{\textwidth}{@{\extracolsep{\fill}}p{.65 \linewidth}p{.35 \linewidth}}
\hline
\multicolumn{1}{l}{Parameter(s)} & \multicolumn{1}{l}{Distribution} \\
\hline
Rebound factor & Uniform\\
NMA parameters - ACR response & Multivariate normal \\
NMA parameters - DAS28 & Multivariate normal \\
NMA parameters - HAQ & Multivariate normal \\
Drug acquisition and administration cost & Fixed \\
Probability of treatment switch at 6 months & Beta \\
Survival model parameters for treatment duration during maintenance phase & Multivariate normal \\
US lifetable mortality rates & Fixed \\
Mortality probability odds ratio - baseline HAQ & Normal \\
Mortality probability hazard ratio - change in HAQ from baseline & Normal\\
ACR response to EULAR response mapping & Dirichlet \\
ACR response to SDAI mapping & Uniform \\
ACR response to CDAI mapping & Uniform \\
ACR response to HAQ mapping & Normal \\
EULAR response to HAQ mapping & Normal \\
Linear HAQ progression - by therapy & Normal \\
Linear HAQ progression - by age & Normal \\
Latent class growth model for HAQ progression & Normal \\
Utility model - \cite{alava2013relationship} mixture model & Multivariate normal \\
Utility model - \citet{wailoo2006modeling} & Normal \\
Hospital costs - hospital days by HAQ & Gamma \\
Hospital costs - hospital costs per day & Gamma \\
General management cost & Gamma \\
Serious infection - survival parameters & Normal \\
Serious infection - cost per infection & Uniform \\
Serious infection - utility loss & Uniform \\
\hline
\end{tabularx}
\scriptsize
%Notes: 
\end{threeparttable}
\end{center}
\end{table}


\subsection{Structural uncertainty}\label{stuctural-uncertainty}
We consider structural uncertainty due to two factors:

\begin{itemize}
\item The relationhip between health states within the model.
\item The statistical model used to estimate parameters.
\end{itemize}

Both sources of uncertainty are reflected in \autoref{tbl:competing-structures}. The choice of model structure for the initial treatment phase (\textbf{H1-H3} and \textbf{S1-S6}) depends on the preferred measures of disease included in the model as well as whether statistical relationships should be modeled directly or indirectly. Likewise, the choice of model for HAQ progression, treatment duration, and converting HAQ to utility all reflect uncertainty in the appropriate statistical model. 


\subsection{Implementation}\label{implementation}
We begin by describing the simulation procedure conditional on model structure, which uses PSA to capture uncertainty within but not between models. The procedure proceeds in two steps: first, model parameters are sampled from their joint probability distribution (\autoref{parameter-uncertainty}), and second, for each parameter set, model outcomes are simulated one at a time for individual patients in the specified population (\autoref{sec:populations}).   

Analysts who wish to expand the analysis to capture uncertainty between models can follow the approach described in \citet{bojke2009characterizing}. In particular, for each randomly sampled parameter set, each model structure (or a subset of plausible model structures) can be simulated. The distribution of simulated outcomes across parameters and models will then reflect uncertainty both within and between models. 

Its important to note that simulation output for an individual patient captures differences in outcomes across patients due to random variation (often referred to as first order uncertainty). This information might be useful to patients since it is needed to predict the distribution of their future outcomes conditional on their characteristics, but less useful to a decision maker concerned with making treatment decisions for a population or subset of a population. Analysts wishing to use the model for CEA should therefore estimate mean outcomes by averaging over the simulated patients for each parameter set and model structure. The number of simulated patients should be sufficiently large so that mean outcomes are stable across model runs (i.e., first order uncertainty is eliminated). 

Although CEA is concerned with mean outcomes, that does not imply that it does not account for heterogeneity. Instead, since outcomes depend on the characteristics of each patient, model averages are a function of the population analyzed. Subgroup analyses can be used to examine differences in cost-effectiveness across subgroups by simulating patients with certain shared characteristics. 

Parameter and structural uncertainty imply decision uncertainty, or the degree to which decisions are made based on imperfect knowledge. Indeed, with the aim to maximize health outcomes for a given budget, the optimal decision with current information is to choose the policy that maximizes the expected NMB; however, due to uncertainty, the incorrect policy may be considered the most cost-effective. To characterize this uncertainty, standard summary measures including 95\% credible intervals for NMBs and other model outcomes, cost-effectiveness planes, and cost-effectiveness acceptability curves, and the expected value of perfect information can be calculated from the simulated output. Since the expected value of partial perfect information is computationally costly, it can be approximated using meta-modeling techniques \citep{jalal2013linear, jalal2015computing, heath2016estimating}.

\begin{appendices}

\section{Mathematical formulas}\label{app:math}
\subsection{Predicted probabilities from a logistic regression} \label{app:logistic-regression}
Predicted probabilities from logistic regressions are calculated using the inverse logit function,
\begin{align}
\hat{p} = \frac{1}{1 + \exp(-x\beta)},
\end{align}
where $\beta$ is a vector of regression coefficients. 

\subsection{Using odds ratios to adjust probabilities}\label{app:odds-ratio-prob}
Let $p_1$ be a baseline probability, $\beta$ be a vector of log odds ratios, and $x$ be a vector of regressors. We apply the log odds ratios to $p_1$ to generate a new probability $p_2$ with the logistic equation,

\begin{align}
p_2 &= \frac{1}{1 + \exp\left[-\left(\logit(p_1) + x^T\beta \right)\right]},
\end{align}

where,

\begin{align}
\logit(p) = \log\left(\frac{p}{1-p}\right)
\end{align}

\subsection{Converting rates and probabilities}\label{app:rate-prob}
Given a \emph{constant} rate $r$ during a given time period, we estimate the probability of an event ocurring before time $t$ using the exponential distribution,

\begin{align}
p(\tau < t |r) &= 1 - e^{-rt}.
\end{align}

Given a probability $p$, the rate parameter is recovered by applying the log transformation,

\begin{align}
r = \frac{-\ln(1-p)}{t}.
\end{align}

\subsection{Calculating standard errors from confidence intervals}\label{app:ci-se}
Journal articles often report confidence intervals rather than standard errors. However, given that regression coefficients are asymptotically normally distributed, standard errors can be calculated from a confidence interval using the normal distribution. In particular, given a coefficient estimate $\beta$ (e.g., a log hazard ratio, log odds ratio, or linear regression coefficient) and an upper bound $u$ and lower bound $l$ of a two-sided 95\% confidence interval, we calculate the standard error as,

\begin{align}
SE(\beta) = \frac{u - l}{2 \cdot \Phi^{-1}(0.975)},
\end{align}

where $\Phi^{-1}(p)$ is the quantile function of the normal distribution. 


\section{Heterogeneous populations}\label{app:population}
When generating heterogeneous patient populations, we sample binary variables from binomial distributions, continuous uncorrelated variables from normal distributions, and continuous correlated variables from multivariate normal distributions. Truncated distributions are used when variables are restricted to lie within certain intervals. More specifically,the proportion of the female population is drawn from a binomial distribution while age, disease duration and the number of previous DMARDs are drawn from truncated normal distributions. Each sampled value of the number of previous DMARDs is rounded to the nearest integer. Baseline HAQ and three disease activity measures (DAS28, SDAI, and CDAI) are drawn from truncated multivariate normal distributions. The covariance matrix is calculated using the correlations reported in \citet{aletaha2005acute} (\autoref{fig:da-cor}).

<<da-cor, echo = FALSE, include = FALSE>>=
args <- formals(sample_pats)
cor <- matrix(NA, nrow = 4, ncol = 4)
cor[1, 1] <- 1
cor[1, 2] <- args$cor_das28_sdai 
cor[1, 3] <- args$cor_das28_cdai
cor[1, 4] <- args$cor_das28_haq
cor[2, 2] <- 1
cor[2, 3] <- args$cor_sdai_cdai
cor[2, 4] <- args$cor_sdai_haq
cor[3, 3] <- 1
cor[3, 4] <- args$cor_cdai_haq
cor[4, 4] <- 1
rownames(cor) <- colnames(cor) <- c("DAS28", "SDAI", "CDAI", "HAQ")
cormat <- melt(cor)
p <- ggplot(cormat, aes(Var2, Var1, fill = value))+
 geom_tile(color = "white")+
 scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
   midpoint = 0.5, limit = c(0,1), space = "Lab", 
    name="Correlation", na.value="transparent") +
  theme_minimal() +
 theme(axis.text.x = element_text(angle = 45, vjust = 1, 
    size = 12, hjust = 1))+
 coord_fixed() +
  geom_text(aes(Var2, Var1, label = value), color = "black", size = 4) +
  theme(panel.grid.major = element_blank(),
        axis.title.x = element_blank(),
        axis.title.y = element_blank(),
         axis.ticks = element_blank(),
        legend.justification = c(1, 0),
         legend.position = c(0.5, 0.75),
        legend.direction = "horizontal") +
         guides(fill = guide_colorbar(barwidth = 7, barheight = 1,
                title.position = "top", title.hjust = 0.5))
ggsave("figs/da-cor.png", p, height = 5, width = 7)
@

\begin{figure}[H]
\centering
\includegraphics[max size={.7\textwidth}{.7\textheight}]{figs/da-cor.png}
\caption{Correlations between disease activity measures and HAQ}\label{fig:da-cor}
\end{figure}

We used the correlations from the routine cohort (during visit 1) rather than correlations in the inception cohort (at baseline) since the correlation between HAQ and the disease activity measures were more similar to those from the Leflunomide database \citep{smolen2003simplified}. That said, correlations between the three disease activity measures were nearly identical in each cohort. The one exception was that the correlation between SDAI and CDAI of 1 in the routine cohort seemed unreasonably high so we used the value of 0.94 from the inception cohort. 

<<pop-app, echo = FALSE, include = FALSE>>=
npats <- 1000
pats <- sample_pats(n = npats, type = "heterog")
tab <- apply_summary(pats)[, c("Mean", "Lower", "Upper")]
rownames(tab) <- c("Age", "Male", "Weight (kg)", "Disease duration", "Previous DMARDs",
                   "DAS28", "SDAI", "CDAI", "HAQ")
tab <- formatC(tab, format = "f", digits = 2)
tex <- print(xtable(tab), 
      include.rownames = TRUE, include.colnames = FALSE,
      only.contents = TRUE, sanitize.text.function = identity,
      file = "tables/pats-samp.txt")
@


We used this sampling procedure to simulate \Sexpr{formatC(npats, format = "d", big.mark = ",")} patients. Summary statistics from the simulated patient cohort are \Sexpr{formatC(npats, format = "d", big.mark = ",")} are shown in \autoref{tbl:pats-samp}.

\begin{table}[!ht]
\begin{center}
\begin{threeparttable}
\caption{Summary of characteristics for 1,000 simulated patients} \label{tbl:pats-samp}
\begin{tabularx}{\textwidth}{@{\extracolsep{\fill}}lccc}
\hline
\multicolumn{2}{c}{} & \multicolumn{2}{c}{95 CI\%} \\
\cmidrule{3-4}
\multicolumn{1}{l}{} & \multicolumn{1}{c}{Mean} & \multicolumn{1}{c}{Lower} & \multicolumn{1}{c}{Upper}\\
\hline
\ExpandableInput{tables/pats-samp.txt}
\hline
\end{tabularx}
\scriptsize
\end{threeparttable}
\end{center}
\end{table}

\section{Mapping ACR response to changes in disease activity}\label{app-acr-da}
Let $DA$ denote disease activity, $n_1$ the number of patients with ACR 20-50 response, $n_2$ the number of patients with ACR 50-70 response, $n_3$ the number of patients with ACR 70 response, and $N$ the number of patients with an ACR response greater than or equal to 20\%. Mean changes in SDAI, CDAI, and DAS28 by overlapping ACR response categories are converted to mean changes by mutually exclusive ACR response categories as follows:

\begin{itemize}
\item \textbf{ACR 70}: Mean changes by ACR 70 were reported directly in \citet{aletaha2005simplified}.
\item \textbf{ACR 50-70}: Mean change in disease activity given ACR 50-70 response is calculated by solving for $\E[DA|50 \leq ACR < 70]$:

\begin{align}
\E[DA|ACR \geq 50] = \frac{n_2}{N} \cdot \E[DA|50 \leq ACR < 70]  + \frac{n_3}{N} \cdot \E[DA|ACR \geq 70]
\end{align}

\item Mean change in disease activity given ACR 20-50 response is calculated by solving for $\E[DA|20 \leq ACR < 50]$

\begin{align}
\E[DA|ACR \geq 20] = \frac{n_1}{N} \cdot \E[DA|20 \leq ACR < 50]  + \frac{n_2 + n_3}{N} \cdot \E[DA|ACR \geq 50]
\end{align}

\end{itemize}

\section{HAQ progression}\label{app:haq-progression}
\subsection{Effect of age on linear HAQ progression}\label{app:age-linear-haq}
\citet{michaud2011treatment} report an overall rate of linear HAQ progression and rates for three age groups (<40, 40-64, $\geq$ 65). Let $\beta$ be the overall rate of progression and $\beta_a$ be the rate of progression for age group $a$. To estimate the effect of age on the progression rate, we calculated the difference between the overall progression rate and the age specific rate, $\delta_a = \beta - \beta_a$. We estimated the standard error of this quantity assuming no covariance between $\beta$ and $\beta_a$,

\begin{align}
SE(\delta_a) = \sqrt{SE(\beta)^2 + SE(\beta_a)^2}.
\end{align}


\subsection{HAQ trajectory with a latent class growth model}\label{app:lcgm-haq}
\citet{norton2014health} model HAQ progression using a latent class growth model (LCGM). The probability that individual $i$ is a member of class $c$ at time $t$ is modeled using a multinomial logistic regression,

\begin{align}
P(C_{it} = c) &= \frac{\exp(w_{it}^T\delta_c)}{\sum_{s=1}^{4}\exp(w_{it}^T\delta_s)},
\end{align}

where $\delta_s$ is the vector of regression coefficients associated with class $s$ and $w_{it}$ is the corresponding vector of regressors. The variables included in $w_{it}$ are age, gender, baseline DAS28, symptom duration, rheumatoid factor, ACR criteria, and socioeconomic status. Regression coefficients for classes 2-4 relative to class 1 are shown in \autoref{tbl:lcmm-class-coefs}. Older age and female gender are especially important predictors of membership in higher risk classes; a worse DAS28 score, rheumatoid factor positivity, fullfilment of the 1987 ACR criteria, lower socioeconomic status, and longer disease duration are also predictors of membership in classes with worse HAQ progression. 

<<app-lcgm-class, echo = FALSE, include = FALSE>>=
coefs = copy(haq.lcgm.pars$coef)
coefs[, lower := coef - qnorm(.975) * se]
coefs[, upper := coef + qnorm(.975) * se]

## class membership
coefs.c <- coefs[parameter %in% c("delta2", "delta3", "delta4")]
varnames <- c("Intercept", "Age at onset", "Female gender", "Disease duration (months)",
                 "DAS28 score", "Rheumatoid factor positive", "ACR criteria for RA",
                 "Socioeconomic status")
coefs.c <- coefs.c[, .(parameter, coef, lower, upper)]

# class 2
tab <- coefs.c[parameter == "delta2", !"parameter", with = FALSE]
tab <- formatC(as.matrix(tab), format = "f", digits = 3)
tab <- cbind(paste0("\\;", varnames), tab)
tex <- print(xtable(tab), 
      include.rownames = FALSE, include.colnames = FALSE,
      only.contents = TRUE, sanitize.text.function = identity,
      hline.after = NULL,
      file = "tables/lcgm-coef-class2.txt")

# class 3
tab <- coefs.c[parameter == "delta3", !"parameter", with = FALSE]
tab <- formatC(as.matrix(tab), format = "f", digits = 3)
tab <- cbind(paste0("\\;", varnames), tab)
tex <- print(xtable(tab), 
      include.rownames = FALSE, include.colnames = FALSE,
      only.contents = TRUE, sanitize.text.function = identity,
      hline.after = NULL,
      file = "tables/lcgm-coef-class3.txt")

# class 4
tab <- coefs.c[parameter == "delta4", !"parameter", with = FALSE]
tab <- formatC(as.matrix(tab), format = "f", digits = 3)
tab <- cbind(paste0("\\;", varnames), tab)
tex <- print(xtable(tab), 
      include.rownames = FALSE, include.colnames = FALSE,
      only.contents = TRUE, sanitize.text.function = identity,
      hline.after = NULL,
      file = "tables/lcgm-coef-class4.txt")

## trajectory
coefs.t <- coefs[parameter %in% c("beta1", "beta2", "beta3", "beta4")]
varnames <- c("Intercept", "Linear", "Quadratic", "Cubic")
coefs.t <- coefs.t[, .(parameter, coef, se)]

# class 1
tab <- coefs.t[parameter == "beta1", !"parameter", with = FALSE]
tab <- formatC(as.matrix(tab), format = "f", digits = 3)
tab <- cbind(paste0("\\;", varnames), tab)
tex <- print(xtable(tab), 
      include.rownames = FALSE, include.colnames = FALSE,
      only.contents = TRUE, sanitize.text.function = identity,
      hline.after = NULL,
      file = "tables/lcgm-coef-growth-class1.txt")

# class 2
tab <- coefs.t[parameter == "beta2", !"parameter", with = FALSE]
tab <- formatC(as.matrix(tab), format = "f", digits = 3)
tab <- cbind(paste0("\\;", varnames), tab)
tex <- print(xtable(tab), 
      include.rownames = FALSE, include.colnames = FALSE,
      only.contents = TRUE, sanitize.text.function = identity,
      hline.after = NULL,
      file = "tables/lcgm-coef-growth-class2.txt")

# class 3
tab <- coefs.t[parameter == "beta3", !"parameter", with = FALSE]
tab <- formatC(as.matrix(tab), format = "f", digits = 3)
tab <- cbind(paste0("\\;", varnames), tab)
tex <- print(xtable(tab), 
      include.rownames = FALSE, include.colnames = FALSE,
      only.contents = TRUE, sanitize.text.function = identity,
      hline.after = NULL,
      file = "tables/lcgm-coef-growth-class3.txt")

# class 4
tab <- coefs.t[parameter == "beta4", !"parameter", with = FALSE]
tab <- formatC(as.matrix(tab), format = "f", digits = 3)
tab <- cbind(paste0("\\;", varnames), tab)
tex <- print(xtable(tab), 
      include.rownames = FALSE, include.colnames = FALSE,
      only.contents = TRUE, sanitize.text.function = identity,
      hline.after = NULL,
      file = "tables/lcgm-coef-growth-class4.txt")

@

\begin{table}[!ht] 
\begin{center}
\begin{threeparttable}
\caption{Determinants of class membership in the ERAS cohort} \label{tbl:lcmm-class-coefs}
\begin{tabularx}{\textwidth}{@{\extracolsep{\fill}}lccc}
\hline
\multicolumn{2}{l}{} & \multicolumn{2}{c}{95\% CI} \\
\cmidrule{3-4} 
\multicolumn{1}{l}{} & \multicolumn{1}{c}{Coefficient} & \multicolumn{1}{c}{Lower} & \multicolumn{1}{c}{Upper}  \\
\hline
\multicolumn{4}{@{}l}{\textbf{Class 2: moderate}} \\
\ExpandableInput{tables/lcgm-coef-class2.txt} \\
\multicolumn{4}{@{}l}{\textbf{Class 3: high}} \\
\ExpandableInput{tables/lcgm-coef-class3.txt} \\
\multicolumn{4}{@{}l}{\textbf{Class 4: severe}} \\
\ExpandableInput{tables/lcgm-coef-class4.txt}
\hline
\end{tabularx}
\scriptsize
Notes: Class 1, or the "low" group, is the reference category.
\end{threeparttable}
\end{center}
\end{table}

The HAQ trajectory for a given class can be written as,

\begin{align}\label{eqn:lcgm-haq}
y_{itc}^{*} &= \beta_{0c} + \beta_{1c}x_t + \beta_{2c}x_t^2 + \beta_{3c}x_t^3 + \epsilon_{it} \\
y_{itc} &= 
\begin{cases}
  0 & \text{if}\  y_{itc}^{*} < 0 \\
  y_{itc}^{*}& \text{if}\  0 \leq y_{itc}^{*} \leq 3 \\
   3 & \text{if}\  y_{itc}^{*} > 3 ,
\end{cases}
\end{align}

where $y_{itc}$ is the HAQ score, $x_t$ is a variable that is a function of time, the $\beta_{jc}$ are polynomial regression coefficients for members of class c, and $\epsilon_{it}$ is an error term.

Sam Norton generously provided us with statistical estimates of the 4 class LCGM used in \citet{norton2014health} from \href{https://www.statmodel.com}{MPlus}. Like \citet{stevenson2016adalimumab}, we noted that the coefficient estimates the MPlus resulted in large fluctuations in the predicted HAQ scores, likely because three decimal places was not precise enough for the cubic term in \autoref{eqn:lcgm-haq}. We consequently used the coefficient estimates to predict the probability of class membership---which are less likely to be influenced by the number of reported decimal places---but estimated \autoref{eqn:lcgm-haq} using the observed HAQ values reported in Figure 2 in \citet{norton2014health}. Morevoer, since we are only interested in the HAQ trajectory following the HAQ decline during the initial treatment phase, we limited our analyis to HAQ values from year 2 and onwards. Using the post year 2 data, we estimated {eqn:lcgm-haq} using separate linear regressions with cubic polynomials for each class (\autoref{tbl:lcmm-growth-coefs}). Like \citet{norton2014health}, we set $x_t$ equal to a reciprocal transformation of time,

\begin{align}
x_t &= 1 - \frac{1}{t+1}
\end{align}

\begin{table}[!ht] 
\begin{center}
\begin{threeparttable}
\caption{LCGM HAQ trajectory coefficients} \label{tbl:lcmm-growth-coefs}
\begin{tabularx}{\textwidth}{@{\extracolsep{\fill}}lccc}
\hline
\multicolumn{1}{l}{} & \multicolumn{1}{c}{Coefficient} & \multicolumn{1}{c}{Standard error}  \\
\hline
\multicolumn{3}{@{}l}{\textbf{Class 1: low}} \\
\ExpandableInput{tables/lcgm-coef-growth-class1.txt} \\
\multicolumn{3}{@{}l}{\textbf{Class 2: moderate}} \\
\ExpandableInput{tables/lcgm-coef-growth-class2.txt} \\
\multicolumn{3}{@{}l}{\textbf{Class 3: high}} \\
\ExpandableInput{tables/lcgm-coef-growth-class3.txt} \\
\multicolumn{3}{@{}l}{\textbf{Class 4: severe}} \\
\ExpandableInput{tables/lcgm-coef-growth-class4.txt}
\hline
\end{tabularx}
\scriptsize
Notes: Class 1, or the ``low'' group, is the reference category.
\end{threeparttable}
\end{center}
\end{table}

In the cost-effectiveness model, we simulate the HAQ score at 6 months as a function of the baseline HAQ score and the change in HAQ during the initial treatmment phase. Since the \citet{norton2014health} model is not conditional on the initial HAQ score (i.e., the simulated HAQ score at 6 months), we use it to predict changes in HAQ rather than the level of the HAQ score. More preciseley, for a patient in a given class, we model the change in HAQ as,  

\begin{align}\label{eqn:lcgm-dhaq}
\Delta y_{itc}^{*} &= y_{i,t,c}^{*} - y_{i,t-1,c}^{*} \\
&= \beta_{1c}(x_t - x_{t-1}) + \beta_{2c}(x_t^2 - x_{t-1}^2) + \beta_{3c}(x_t^3-x_{t-1}^3) + (\epsilon_{i,t} - \epsilon_{i,t-1}). \nonumber
\end{align}

Since \autoref{eqn:lcgm-haq} was estimated on aggregated data, we did not have reliable estimates of $\epsilon_{it}$. We consequently set $\epsilon_{i,t} - \epsilon_{i,t-1}$ equal to 0, which implies that we are generating a mean resopnse rather than a predicted response. In other words, we are not simulating the random variation associated with each individual, but are still accurately simulating mean outcomes accross populations or subpopulations. 

\section{Simulating death}\label{ssec:simulating-death}
Death is simulated for each patient during each model cycle based on age, gender, baseline HAQ, and change in HAQ from baseline. A 0/1 death indicator is randomly drawn using the following procedure: 
\begin{enumerate}
\item Find $q_{xg}$, the probability that a patient of gender $g$ and age $x$ will die before age $x+1$, from lifetables.
\item As described in \autoref{app:odds-ratio-prob}, adjust $q_{gx}$ using the effect of a change in baseline HAQ on the odds of mortality, $OR$,
\begin{align}
p_m = \frac{1}{1 + \exp{\left[-(\text{logit}(q_x) + \log(OR)\cdot HAQ)\right]}}.
\end{align}
\item Following \autoref{app:rate-prob}, convert the mortality probability, $p_m$, into a mortality rate, $r_m$.
\begin{align}
r_m &= -log(1 - p_m).
\end{align}
\item Adjust the mortality rate, $r_m$, using the estimated log hazard ratio of mortality, $HR$ of a change in HAQ from baseline, $\Delta$ HAQ.
\begin{align}
r_m &= r_m \cdot \exp[\log(HR) \cdot \Delta HAQ]
\end{align}
\item Following \autoref{app:rate-prob}, convert the mortality rate into a probability given a 6-month cycle length,
\begin{align}
p_m = 1 - \exp[-r_m * (6/12)].
\end{align}
\item Randomly draw a 0/1 death indicator, $d$, given the probability of death, $p_m$,
\begin{align}
d \sim \text{Bin}(1, p_m).
\end{align}
\end{enumerate}

\section{Simulating utility with a mixture model}\label{app:sim-utility-mixture}
The mixture model estimated by \citet{alava2013relationship} simulates utility in two stages. In the first stage, we sampled pain for a given individual in a particular model cycle based on the HAQ score. In the second stage, we simulated utility as a function of HAQ, pain and age/sex.

\subsection{Simulating pain}
To simulate pain from HAQ, we used the summary statistics for pain and HAQ reported in \citet{sarzi2002correlation}. Pain was measured with the visual analog scale (VAS) with mean  $\mu_{pain} =$ \Sexpr{pain$pain.mean} and standard deviation $\sigma_{pain} =$ \Sexpr{formatC(sqrt(pain$pain.var), format = "f", digits = 2)}, while HAQ was reported to have mean $\mu_{haq} =$ \Sexpr{pain$haq.mean} and standard deviation $\sigma_{haq} =$ \Sexpr{formatC(sqrt(pain$haq.var), format = "f", digits = 2)}. 

We then estimated the correlation between pain and HAQ by digitally scanning the curve depicting the (linear) relationship between pain and HAQ (Figure 114) shown in \citet{stevenson2016adalimumab}. Using the scanned data, we regressed pain on HAQ using simple ordinary least squares (OLS). The correlation between pain and HAQ, estimated as $\rho =$ \Sexpr{formatC(pain$painhaq.cor, digits = 2)}, was calculated by rearranging the OLS estimate for the slope, $\beta$, of the regression model,

\begin{align}
\rho = \beta \cdot \frac{\sigma_{haq}}{\sigma_{pain}}.
\end{align}

Pain was simulated using these parameters by assuming that pain was normally distributed conditional on HAQ,

\begin{align}
pain | haq = h \sim N\left (\mu_{pain} + \rho \frac{\sigma_{pain}}{\sigma_{haq}}(h - \mu_{haq}), \sigma^2_{pain}(1 - \rho^2)\right).
\end{align}

However, since the VAS is constrained to lie between 0 and 100, pain was drawn from a truncated normal distribution with a lower limit of 0 and an upper limit of 100. 


\subsection{Simulating utility}
After simulating pain, we simulated utility with a mixture model. Within each class $c$, the HAQ score for patient $i$ in period $t$ was modeled as,

\begin{align}
y_{it|C_{it}} &= 
\begin{cases}
  1 & \text{if}\  y^{*}_{it|C_{it}}>0.883 \\
  y^{*}_{it|C_{it}} & \text{otherwise}
\end{cases}\\
y^{*}_{it|C_{it}} &= \alpha_{ic} +  x_{it}^T\beta_{c} + \epsilon_{it}\\
\alpha_{ic} &=  \gamma_{c} + z_{i}^T\kappa + \mu_{i},
\end{align}

where $\epsilon_{it}$ is a random error term and $\beta_{c}$ is a vector of regression coefficients corresponding to the vector of variables $x_{it}$. $\alpha_{ic}$ is a random intercept for individual $i$ and class $c$ that is predicted by a class-specific intercept, $\gamma_c$, a vector of individual-specific variables $z_{i}$, a coefficient vector $\kappa$, and an error term, $\mu_i$. Variables included in $x_{it}$ are $HAQ$, $HAQ^2$, $Pain/100$, $Age/10$, and $Age/100$; $z_{i}$ contains a single indicator variable, $Male$, equal to 1 if the patient is male and 0 if female.

The probability of class membership was modeled using a multinomial logit model,

\begin{align}
P(C_{it} = c) &= \frac{\exp(w_{it}^T\delta_c)}{\sum_{s=1}^{4}\exp(w_{it}^T\delta_s)},
\end{align}

where there are four possible classes and $\delta_c$ is a vector of coefficients correpsonding to the vector of variables, $w_{it}$ (which includes an intercept). Variables included in $w_{it}$ other than the intercept are $HAQ$, $Pain/100$, and $Pain/100^2$.

We sampled from the mixture model as follows.

\begin{enumerate}
\item For each individual $i$, sample the error term, $\mu_{i} \sim N(0, \sigma^2_\mu)$.
\item For each individual $i$ and time-period $t$: 
\begin{enumerate}
\item Sample class membership conditional on $w_{it}$; that is, sample $C_{it} \sim \rm{Cat}(p_1, p_2, p_3, p_4)$ where $p_c$ is the probability of being in class $c$.
\item Predict the intercept $\alpha_{ic}$.
\item Sample the error term, $\epsilon_{it} \sim N(0, \sigma^2_\epsilon)$.
\item Predict the HAQ score, $y_{it}$. 
\end{enumerate}
\end{enumerate}

\section{Network Meta-Analysis}\label{appendix:NMA}

\subsection{Systematic literature review}\label{systematic-literature-review}

\textbf{Population}
\begin{itemize}
\item
  Adult (\textgreater{}18 years) patients with moderate to severe RA who
  have had inadequate response to cDMARDs
\end{itemize}

\textbf{Interventions and comparators}

\begin{itemize}
\item
  Biologics as monotherapy or in combination with cDMARDs (adalimumab,
  certolizumab pegol, etanercept, golimumab, infliximab, abatacept,
  rituximab, tocilizumab, sarilumab, tofacitinib, baricitinib)
\item
  Triple therapy (MTX, HCQ, and SSZ)
\item
  cDMARDs alone or in combination (MTX, HCQ, SSZ or LEF)
\end{itemize}

\textbf{Outcomes}
\begin{itemize}
\item
  ACR20/ACR50/ACR70
\item
  DAS28
\item
  Total sharp score
\item
  HAQ-DI score
\item
  SF-36 PCS and MCS
\item
  EQ-5D (VAS and utility scores)
\item
  AEs leading to drop-outs
\end{itemize}

\begin{itemize}
\item
  Randomized controlled trials
\end{itemize}

\textbf{Other}

\begin{itemize}
\item
  Studies published in English
\item
  Primary study available as full text published manuscript only; no
  study available as a conference abstract only was included with the
  exception of abstracts pertaining to investigational products,
  baricitinib and sarilumab
\end{itemize}

\subsection{Criteria for studies to be selected from the systematic
literature review and included in the
NMA}\label{criteria-for-studies-to-be-selected-from-the-systematic-literature-review-and-included-in-the-nma}

The following criteria were used to select relevant studies to be included in the NMA:

\textbf{Population}

\begin{itemize}
\item
  Adult (\textgreater{}18 years) patients with moderate to severe RA who
  have had inadequate response to cDMARDs and are bDMARD-naive
\end{itemize}

\textbf{Interventions}

\begin{itemize}
\item
  Biologics as monotherapy or in combination with cDMARDs (adalimumab,
  certolizumab pegol, etanercept, golimumab, infliximab, abatacept,
  rituximab, tocilizumab, sarilumab, tofacitinib, baricitinib)
\end{itemize}

\textbf{Comparators}

\begin{itemize}
\item
  cDMARDs
\item
  Any active comparator that allows for an indirect comparison between
  the bDMARDs of interest
\end{itemize}

\textbf{Outcomes}

\begin{itemize}
\item
  ACR20/ACR50/ACR70 at 6 months follow-up
\end{itemize}

\subsection{Identified evidence base}\label{identified-evidence-base}

\autoref{fig:study-selection} summarizes the study identification and
selection process. Of the 181 studies included in the large systematic
literature review, 79 studies concerned the bDMARD-naive population
(table NMA studies). There were 66 studies evaluating 36 interventions
for which ACR response criteria were reported at 6 months (with a
tolerability window of \(\pm 4\) weeks). The corresponding evidence
network is presented in \autoref{fig:nma-network-acr-naive}. For the
network meta-analysis the following were deemed to be clinically
equivalent and were pooled.

\begin{itemize}
\item
  ``INF 3mg/kg q8w'' or ``INF 5mg/kg q8w'' or ``INF 6mg/kg q8w''
\item
  ``ETN 50mg qw'' or ``ETN 25mg biw''
\item
  ``ABA 10mg/kg q4wa or''ABA SC 125mg qw"
\item
  ``CER 200mg q2w+MTX'' or ``CER 400mg q4w+MTX
\item
  DMARDs including methotrexate, sulfasalazine, hydroxychloroquine,
  leflunomide at any dosage; studies which only described DMARD therapy
  as conventional or nonbiologic
\end{itemize}

\begin{figure}
\centering
\includegraphics[max size={\textwidth}{\textheight}]{study-selection.png}
\caption{Study identification and selection}\label{fig:study-selection}
\end{figure}

\begin{figure}
\centering
\includegraphics{nma-network-acr-naive.pdf}
\caption{Bayesian random effects NMA network diagram for patients naive
to bDMARDs}\label{fig:nma-network-acr-naive}
\end{figure}

\subsection{Statistical models for network-meta analysis}\label{nma-statistical-models}

\subsubsection{ACR 20/50/70 response} \label{nma-acr}
The probability of ACR20/50/70 responses was estimated using a Bayesian (random effects) network meta-analyses model for ordered categorical data \citep{dias2013evidence}. The model assumes that there is an underlying continuous variable (ACR20/50/70) categorized by specifying different cutoffs corresponding to the point at which an individual moves from one category to the next in each trial. The advantage of this approach over an analysis that considers ACR categories separately is that all possible outcomes are analyzed simultaneously based on the same randomized controlled trials, allowing for consistent estimates by category. To avoid influencing the observed results by prior belief, uninformative prior distributions were used for the estimated model parameters. The relative treatment effects for each bDMARD versus cDMARDs estimated on the probit scale were transformed into absolute probabilities of the nonoverlapping ACR response categories by combining them with the average results for cDMARDs. The posterior distributions of parameters of interest were summarized by the median as a reflection of the point estimate and 95\% credible intervals, constructed from the 2.5 and 97.5 percentiles. Analyses were performed with the Markov chain Monte Carlo method using the JAGS software package (\url{http://mcmc-jags.sourceforge.net/}).

\begin{table}[!ht]
\begin{center}
\begin{threeparttable}
\caption{A comparison of NICE and IVI estimates of ACR response probabilities} \label{tbl:nma-acr-nice-vs-ivi}
\begin{tabularx}{\textwidth}{@{\extracolsep{\fill}}lrrrrrr}
\hline
\multicolumn{1}{c}{} & \multicolumn{3}{c}{IVI} & \multicolumn{3}{c}{NICE}\\
\cmidrule(lr){2-4} \cmidrule(lr){5-7}
\multicolumn{1}{l}{} & \multicolumn{1}{c}{ACR20} & \multicolumn{1}{c}{ACR50} & \multicolumn{1}{c}{ACR70} & \multicolumn{1}{c}{ACR20} & \multicolumn{1}{c}{ACR50} & \multicolumn{1}{c}{ACR70}\\
\hline
\ExpandableInput{tables/nma-acr-nice-vs-ivi.txt}
\hline
\end{tabularx}
\scriptsize
Notes: ACR20/50/70 categories are the probability of at least a 20/50/70\% improvement. 95\% credible intervals are in parentheses. IVI estimates are based on 6-month simulations of 1,000 patients and 1,000 parameters sets for each therapy. NICE estimates are from Table 37 in \citet{stevenson2017cost}. cDMARDs = conventional disease-modifying antirheumatic drugs; MTX = methotrexate; ABT IV = abatacept intravenous; ADA = adalimumab; ETN = etanercept; GOL = golimumab; IFX = infliximab; TCZ = tocilizumab; CZP = certolizumab pegol; ABT SC = abatacept subcutaneous; RTX = rituximab; TOF = tofacitinib. ACR = American College of Rheumatology.
\end{threeparttable}
\end{center}
\end{table}

\subsubsection{HAQ}\label{nma-haq}

\subsubsection{DAS28}\label{nma-das28}

\end{appendices}

\pdfbookmark[1]{References}{References}
\bibliography{../../vignettes/vignettes}

\end{document}